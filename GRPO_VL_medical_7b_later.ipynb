{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ae7805",
   "metadata": {},
   "source": [
    "--- 18/08/2025 kotla sai charan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beec4bf-1304-4321-8746-6e1d9174b8ac",
   "metadata": {
    "id": "4beec4bf-1304-4321-8746-6e1d9174b8ac"
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps -U transformers==4.52.4\n",
    "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "!pip install --no-deps -U bitsandbytes accelerate xformers==0.0.29.post3 peft==0.15.2 trl==0.18.2 cut_cross_entropy \n",
    "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "!pip install --no-deps 'unsloth==2025.6.12' 'unsloth_zoo==2025.6.8'\n",
    "!pip install 'triton==3.2.0' safetensors regex tokenizers\n",
    "!pip install evaluate nltk bert_score rouge_score spacy\n",
    "!pip install --pre --upgrade --no-cache-dir torch torchvision --extra-index-url https://download.pytorch.org/whl/nightly/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "421139af-fa0b-4da2-949b-6ee45a7e5bf2",
   "metadata": {
    "id": "421139af-fa0b-4da2-949b-6ee45a7e5bf2",
    "outputId": "2228ea3d-93e1-40f6-d675-e8b556d773ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vlm-grpo'...\n",
      "remote: Enumerating objects: 246, done.\u001b[K\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
      "remote: Total 246 (delta 46), reused 48 (delta 30), pack-reused 174 (from 1)\u001b[K\n",
      "Receiving objects: 100% (246/246), 787.19 KiB | 3.17 MiB/s, done.\n",
      "Resolving deltas: 100% (130/130), done.\n",
      "/charan_work/vlm-grpo\n",
      "Obtaining file:///charan_work/vlm-grpo\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting accelerate (from vlm-grpo==0.1)\n",
      "  Using cached accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting bitsandbytes (from vlm-grpo==0.1)\n",
      "  Using cached bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting cut_cross_entropy (from vlm-grpo==0.1)\n",
      "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting datasets (from vlm-grpo==0.1)\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting hf_transfer (from vlm-grpo==0.1)\n",
      "  Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting huggingface_hub (from vlm-grpo==0.1)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting peft==0.15.2 (from vlm-grpo==0.1)\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vlm-grpo==0.1) (6.31.1)\n",
      "Collecting regex (from vlm-grpo==0.1)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting safetensors (from vlm-grpo==0.1)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sentencepiece (from vlm-grpo==0.1)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tokenizers (from vlm-grpo==0.1)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "INFO: pip is looking at multiple versions of vlm-grpo to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.6.0+cu124 (from vlm-grpo) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.6.0+cu124\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/GAD-cell/vlm-grpo.git\n",
    "%cd vlm-grpo\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57d0fb",
   "metadata": {},
   "source": [
    "you must run this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188081ce-de5e-456b-9239-160656c48d2e",
   "metadata": {
    "id": "188081ce-de5e-456b-9239-160656c48d2e",
    "outputId": "8f9522a1-7354-46d5-d21e-bb19ddf36966",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/charan_work/vlm-grpo/vlmgrpo/patches/unsloth_patch.py:100: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  name = re.sub(\"\\.([\\d]{1,})\\.\", r\"[\\1].\", name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth patched for VLMs GRPO training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.9.0.dev20250723+cu128)\n",
      "    Python  3.12.9 (you have 3.12.11)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import vlmgrpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387fcf49-cfcf-4347-8dec-37dba75510aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import peft\n",
    "peft.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9ec0f-7915-492b-92b2-8b68ef955159",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5ba2c8281d3d4cd0b967a9c79d184ce0",
      "8508349c0acd4b38a74b130a15e22f92",
      "b8262ca15ba14774b9f338b71e637b41",
      "7ccccd1cead74547aba5de0fa9d5f122",
      "0b33cd29384048c0b10a3fb53bb4af72",
      "613e291fc20041868fc9d22a7f247422",
      "5b61c59c81fd43e9918bf6479542b6cb",
      "1ecc5f32fed44d209f9b2eab7106df90",
      "059375a4600d40e597797d9e303acec0",
      "e1992096ad284814985e84724ac9390f",
      "8939251d4920414793cda5cb188b014b",
      "0210215a1c8b441e97d466902b0c3fa3"
     ]
    },
    "id": "b4c9ec0f-7915-492b-92b2-8b68ef955159",
    "outputId": "64e24428-5cd8-4ac8-887e-e9c4063ffdff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.12: Fast Qwen2_5_Vl patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 5070 Ti. Num GPUs = 1. Max memory: 15.479 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0.dev20250723+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75141609188347ceb76a5bffdfb0cae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c410c149b4a4184be3eca9ec1028d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf490bf91ce4ec9a237b031c7410b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97f002f25d746c8a80fd083e1404e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9702007789544cb7acb88871e45a5319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28838c095c1e49e1be721c3b28e1dc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a369e1194bc445ab527a3c92b7bca37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d4809fad4d4c3faab67cf76882669a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ee316648a0407dbff2bd465f30360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adc69c1e62c4f3c9d0a8f3fe04afc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e350bc8799584ef0b4a95f4cb8a28c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5991041295469e9b4f82267881c265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\",\n",
    "    # 'Cherran/VL_lr_5e5_medical_qwen2point5_7b',\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb62436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FastVisionModel.get_peft_model(\n",
    "#     model,\n",
    "#     finetune_vision_layers     = True, # False if not finetuning vision layers\n",
    "#     finetune_language_layers   = True, # False if not finetuning language layers\n",
    "#     finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "#     finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "#     r = 32,\n",
    "#     lora_alpha = 32,\n",
    "#     lora_dropout = 0,\n",
    "#     bias = \"none\",\n",
    "#     random_state = 3407,\n",
    "#     use_rslora = False,\n",
    "#     loftq_config = None, # And LoftQ\n",
    "#     # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b27d4ceb-4e14-4dde-9059-35288d57f43e",
   "metadata": {
    "id": "b27d4ceb-4e14-4dde-9059-35288d57f43e",
    "outputId": "0d3f0240-ddb0-4f3b-d2e0-ff12707cdccb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca415e6178b4adba3c66be87259f4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc8ac920cb24f7998a327962df27cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/82.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf152d92b514439fafa4e184262a52dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'post', 'image_desc', 'prompt', 'summary', 'drug_names', 'non_physical_adverse_effects', 'physical_adverse_effects'],\n",
       "    num_rows: 735\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('Cherran/train_extra_rewards_GRPO_medical_summaries', split = 'train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d7ebab-2663-4642-ab14-fc96e4a898a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4ec96",
   "metadata": {},
   "source": [
    "This code is not working for multiple images, so removed all images with len>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a781b31-259f-4f38-b253-be74e53d6bd2",
   "metadata": {
    "id": "4a781b31-259f-4f38-b253-be74e53d6bd2",
    "outputId": "56c5b0f0-f6b3-40a8-e092-3cdf11ba702c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a6d6f2fdc4fffaf483a6011584d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'post', 'image_desc', 'prompt', 'summary', 'drug_names', 'non_physical_adverse_effects', 'physical_adverse_effects'],\n",
       "    num_rows: 731\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda sample: len(sample['image']) <= 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ed808-883d-42bc-9122-194078b3798b",
   "metadata": {
    "id": "dd0ed808-883d-42bc-9122-194078b3798b"
   },
   "outputs": [],
   "source": [
    "def convert_to_conversation(sample):\n",
    "\n",
    "    resized_images = []\n",
    "    for image_object in sample[\"image\"]:\n",
    "        resized_images.append(image_object.resize((512, 512)))\n",
    "\n",
    "    user_content = [\n",
    "        {\"type\": \"text\", \"text\": sample['prompt']}\n",
    "    ]\n",
    "\n",
    "    for resized_image_object in resized_images:\n",
    "        user_content.append(\n",
    "            {\"type\": \"image\", \"image\": resized_image_object}\n",
    "        )\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_content\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"prompt\": conversation,\n",
    "        \"image\": resized_images,\n",
    "        \"image_desc\": sample['image_desc'],\n",
    "        \"answer\": sample['summary'],\n",
    "        \"drug_names\" : sample['drug_names'],\n",
    "        \"physical_adverse_effects\" : sample['physical_adverse_effects'],\n",
    "         \"non_pdv\" : sample['non_physical_adverse_effects']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d2200",
   "metadata": {},
   "source": [
    "#### Adding dummy image is important, this repo https://github.com/GAD-cell/vlm-grpo.git is not supporting as of today 18/08/2025 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacab8f-ed38-4980-8653-1480ca754f2d",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d239cc5bdb464d7fa2246f91de7c735c"
     ]
    },
    "id": "7cacab8f-ed38-4980-8653-1480ca754f2d",
    "outputId": "84f46983-e3f4-45dd-99c1-5e3ec22d88f5",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9c6891336141b39a34168eaba491b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "dummy_image = Image.new('RGB', (512, 512), color = 'black')\n",
    "\n",
    "def add_dummy_image(example):\n",
    "    if not example[\"image\"]:\n",
    "        example[\"image\"] = [dummy_image]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(add_dummy_image)\n",
    "converted_dataset = [convert_to_conversation(sample) for sample in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b53837a-d326-4bc3-b913-60518fc4e4f3",
   "metadata": {
    "id": "5b53837a-d326-4bc3-b913-60518fc4e4f3",
    "outputId": "31c32cde-99d1-441f-f359-bbf5bb731c00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You are an excellent medical paragraph generator. I have drug names and Adverse Drug reactions Keywords. Consolidate all information in one paragrah without adding any extra knowledge or text.\\n  drug_names: Taxol\\n  physical_adverse_effects: Pain in left hand/thumb, port protruding through skin, brace on hand\\n\\n  Strcitly output the paragraph no explanations.\\n'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.Image.Image image mode=RGB size=512x512>}]}],\n",
       " 'image': [<PIL.Image.Image image mode=RGB size=512x512>],\n",
       " 'image_desc': '',\n",
       " 'answer': 'Taxol has been associated with adverse effects including pain in the left hand/thumb, a port protruding through the skin, and the necessity of a brace on the hand.',\n",
       " 'drug_names': 'Taxol',\n",
       " 'physical_adverse_effects': 'Pain in left hand/thumb, port protruding through skin, brace on hand',\n",
       " 'non_pdv': 'Feeling of frustration or hopelessness (\"can\\'t catch a break\")'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4baab-ccdb-4f97-a08a-8f8be8d8d379",
   "metadata": {
    "id": "2fe4baab-ccdb-4f97-a08a-8f8be8d8d379",
    "outputId": "ed58b069-3b97-4e4d-b2bd-227261985b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The disk size of 'converted_dataset' is 50.94754409790039 bytes.\n"
     ]
    }
   ],
   "source": [
    "dataset_size_bytes = dataset.dataset_size\n",
    "\n",
    "print(f\"The disk size of 'converted_dataset' is {dataset_size_bytes/1024/1024} bytes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eI_XKuXNCMvJ",
   "metadata": {
    "id": "eI_XKuXNCMvJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ce9bf21ddf46bca7cd466ac24e67e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_rouge_l(prediction: str, reference: str) -> float:\n",
    "    result = rouge.compute(predictions=[prediction], references=[reference], rouge_types=[\"rougeL\"])\n",
    "    return result[\"rougeL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6utmJsvJCQen",
   "metadata": {
    "id": "6utmJsvJCQen"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import numpy as np\n",
    "def compute_bleu(prediction: str, reference: str) -> float:\n",
    "    ref_tokens = [reference.split()]  # BLEU expects list of reference sentences\n",
    "    pred_tokens = prediction.split()\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    return sentence_bleu(ref_tokens, pred_tokens, weights=(1, 0, 0, 0), smoothing_function=smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "HBTAK-PzCgaf",
   "metadata": {
    "id": "HBTAK-PzCgaf"
   },
   "outputs": [],
   "source": [
    "def compute_reward(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    rewards = []\n",
    "    for res, ans in zip(responses, answer):\n",
    "      if res == ans :\n",
    "          reward = 1.2\n",
    "          rewards.append(reward)\n",
    "          continue\n",
    "\n",
    "      reward = 0.0\n",
    "      rouge_l = compute_rouge_l(res, ans)\n",
    "      bleu = compute_bleu(res, ans)\n",
    "      reward += (rouge_l)*0.6 + bleu*0.4\n",
    "\n",
    "      rewards.append(reward)\n",
    "\n",
    "    print(f\"len of rewards : f{len(rewards)} and avg reward {sum(rewards)/len(rewards)}\")\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "zZh11OGGEnyj",
   "metadata": {
    "id": "zZh11OGGEnyj"
   },
   "outputs": [],
   "source": [
    "def length_reward(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    q = prompts[0][-1]['content']\n",
    "    rewards = []\n",
    "\n",
    "    avg_answer_len = np.mean([len(ans.split()) for ans in answer])\n",
    "    sigma = avg_answer_len * 0.25\n",
    "\n",
    "    for res, ans in zip(responses, answer):\n",
    "        len_res = len(res.split())\n",
    "        len_ans = len(ans.split())\n",
    "\n",
    "        len_diff = abs(len_res - len_ans)\n",
    "\n",
    "        # Gaussian reward function: e^(-(x^2) / (2 * sigma^2))\n",
    "        # This gives a reward of 1.0 for a perfect match, smoothly decreasing to 0.\n",
    "        reward = np.exp(-0.5 * (len_diff / sigma) ** 2)\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c80b0225-1aed-4c5a-a0a6-145632590e62",
   "metadata": {
    "id": "c80b0225-1aed-4c5a-a0a6-145632590e62"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def drug_adverse_preservation_reward(prompts, completions, answer, drug_names, physical_adverse_effects, non_pdv, **kwargs) -> list[float]:\n",
    "    \"\"\"\n",
    "    Calculates a total reward for each response by summing two separate binary rewards:\n",
    "    1. A reward for correctly listing drugs for that specific response.\n",
    "    2. A reward for correctly listing adverse effects for that specific response.\n",
    "    The maximum possible reward for each response is 2.0.\n",
    "    \"\"\"\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "    rewards = []\n",
    "\n",
    "    # Zip all corresponding lists together to process each response with its unique ground truth.\n",
    "    for res, pmpt, drugs_str, physical_effects_str, non_pdv_str in zip(\n",
    "        responses, prompts, drug_names, physical_adverse_effects, non_pdv\n",
    "    ):\n",
    "        res_lower = res.lower()\n",
    "\n",
    "        drug_set = {d.strip().lower() for d in drugs_str.split(',') if d.strip()}\n",
    "\n",
    "        all_drugs_found = all(drug in res_lower for drug in drug_set)\n",
    "        drug_reward = 0.5 if all_drugs_found else 0.0\n",
    "\n",
    "        is_physical_prompt = 'physical_adverse_effects:' in pmpt\n",
    "\n",
    "        adverse_effects_str = physical_effects_str if is_physical_prompt else non_pdv_str\n",
    "\n",
    "        adverse_set = {a.strip().lower() for a in adverse_effects_str.split(',') if a.strip()}\n",
    "\n",
    "        all_adverse_effects_found = all(effect in res_lower for effect in adverse_set)\n",
    "        adverse_reward = 0.5 if all_adverse_effects_found else 0.0\n",
    "\n",
    "        total_reward = drug_reward + adverse_reward\n",
    "        # print(total_reward)\n",
    "        rewards.append(total_reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "o6ZHFCYN9kPG",
   "metadata": {
    "id": "o6ZHFCYN9kPG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded and using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import spacy\n",
    "from PIL import Image\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "NLP_MODEL = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "CLIP_PROCESSOR = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "CLIP_MODEL = AutoModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE)\n",
    "\n",
    "print(f\"Models loaded and using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "WW1zeSff926Z",
   "metadata": {
    "id": "WW1zeSff926Z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "CLIP_DEVICE = DEVICE\n",
    "# CLIP_MODEL.to(CLIP_DEVICE)\n",
    "\n",
    "def calculate_visual_grounding_reward(\n",
    "    completions: list, \n",
    "    image: list, \n",
    "    image_desc: list, \n",
    "    **kwargs  \n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Calculates a reward based on how well the completion is grounded in the image content.\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    \n",
    "    # Safely extract responses\n",
    "    responses = [\n",
    "        comp[0].get('content', '') if comp and isinstance(comp, list) and comp[0] else '' \n",
    "        for comp in completions\n",
    "    ]\n",
    "\n",
    "    for response, img_item, img_desc in zip(responses, image, image_desc):\n",
    "        # --- 1. Input Validation ---\n",
    "        if not response or not img_desc:\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            if not img_item:\n",
    "                logging.warning(\"Empty image list encountered. Skipping.\")\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "            img_input = img_item[0]\n",
    "            \n",
    "            \n",
    "            if img_input.getbbox() is None:\n",
    "                logging.warning(\"Image is blank or all black. Skipping.\")\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "        except (FileNotFoundError, IndexError) as e:\n",
    "            logging.error(f\"Could not process image: {e}. Skipping.\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # --- 2. Extract Key Phrases from Description ---\n",
    "        doc = NLP_MODEL(img_desc.lower())\n",
    "        all_chunks = list({chunk.text.strip() for chunk in doc.noun_chunks if chunk.text.lower() not in STOP_WORDS})\n",
    "\n",
    "        if not all_chunks:\n",
    "            logging.info(f\"No usable noun chunks found in description: '{img_desc}'.\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # --- 3. Score Phrases against Image using CLIP ---\n",
    "        try:\n",
    "            # Performance: Move inputs directly to the model's device\n",
    "            inputs = CLIP_PROCESSOR(\n",
    "                text=all_chunks,\n",
    "                images=img_input,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True\n",
    "            ).to(CLIP_DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = CLIP_MODEL(**inputs)\n",
    "            \n",
    "            # Get scores and find top 3 visually grounded chunks\n",
    "            scores = outputs.logits_per_image.squeeze()\n",
    "            chunk_scores = sorted(zip(all_chunks, scores), key=lambda x: x[1], reverse=True)\n",
    "            top_chunks_with_scores = chunk_scores[:2]\n",
    "            \n",
    "            top_chunks = [item[0] for item in top_chunks_with_scores]\n",
    "            top_scores = torch.tensor([item[1] for item in top_chunks_with_scores])\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during CLIP processing for '{img_desc}': {e}\")\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        # --- 4. Calculate Final Weighted Reward ---\n",
    "        weights = F.softmax(top_scores, dim=0)\n",
    "        final_reward = 0.0\n",
    "        response_lower = response.lower()\n",
    "        print(top_chunks)\n",
    "        for i, chunk in enumerate(top_chunks):\n",
    "            if chunk in response_lower:\n",
    "                final_reward += weights[i].item()\n",
    "        \n",
    "        rewards.append(final_reward)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f970db-1bc7-491e-937d-b0fbb209022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch, torch.nn.functional as F\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"manueldeprada/FactCC\")\n",
    "clf = AutoModelForSequenceClassification.from_pretrained(\"manueldeprada/FactCC\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba4b81-1624-4248-b913-cbb6a60c2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def factual_consistency_reward(\n",
    "    source_texts: list[str],\n",
    "    completions: list[str],\n",
    "    rescale_floor: float = 0.875,\n",
    "    sensitivity: float = 3.0,\n",
    "    **kwargs\n",
    ") -> list[float]:\n",
    "    rewards = []\n",
    "    responses = [completion[0]['content'] for completion in completions]\n",
    "\n",
    "    for src, hyp in zip(source_texts, responses):\n",
    "        inputs = tok(src, hyp, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = clf(**inputs).logits.squeeze()\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            prob_consistent = probs[1].item()\n",
    "\n",
    "            if prob_consistent < rescale_floor:\n",
    "                rescaled_prob = 0.0\n",
    "            else:\n",
    "                rescaled_prob = (prob_consistent - rescale_floor) / (1.0 - rescale_floor)\n",
    "            reward = rescaled_prob ** sensitivity\n",
    "            rewards.append(reward)\n",
    "\n",
    "    return rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E1znlwnpmgTj",
   "metadata": {
    "id": "E1znlwnpmgTj"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def domain_specific_hallucination_penalty(\n",
    "    prompts: list[str],\n",
    "    completions: list[str],\n",
    "    answer: list[str],\n",
    "    drug_names: list[str],\n",
    "    image_desc: list[str],\n",
    "    physical_adverse_effects: list[str],\n",
    "    non_pdv: list[str],\n",
    "    **kwargs\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Penalizes the model for generating noun phrases not found in the source\n",
    "    context or a pre-defined list of domain-specific terms.\n",
    "    \"\"\"\n",
    "    \n",
    "    responses = [\n",
    "        comp[0].get('content', '') if comp and isinstance(comp, list) and comp[0] else '' \n",
    "        for comp in completions\n",
    "    ]\n",
    "    \n",
    "    base_texts = [(ans + \" \" + img_des).lower() for ans, img_des in zip(answer, image_desc)]\n",
    "    response_texts = [res.lower() for res in responses]\n",
    "\n",
    "    # --- 2. Efficient Batch Processing with nlp.pipe ---\n",
    "    \n",
    "    # Process all source and response texts at once for a major speedup.\n",
    "    base_docs = list(nlp.pipe(base_texts))\n",
    "    response_docs = list(nlp.pipe(response_texts))\n",
    "\n",
    "    # --- 3. Main Loop ---\n",
    "    \n",
    "    rewards = []\n",
    "    iterator = zip(\n",
    "        base_docs, response_docs, drug_names, physical_adverse_effects, non_pdv\n",
    "    )\n",
    "\n",
    "    for base_doc, res_doc, drugs_str, effects_str, non_effects_str in iterator:\n",
    "        \n",
    "        # --- 4. Build Whitelist of Allowed Chunks ---\n",
    "        \n",
    "        # Extract noun chunks from the pre-processed base document\n",
    "        allowed_chunks = {\n",
    "            chunk.text.strip() for chunk in base_doc.noun_chunks \n",
    "            if chunk.text not in STOP_WORDS\n",
    "        }\n",
    "\n",
    "        # Add known domain-specific terms to the whitelist\n",
    "        known_drugs = {drug.strip().lower() for drug in drugs_str.split(',') if drug.strip()}\n",
    "        known_effects = {effect.strip().lower() for effect in effects_str.split(',') if effect.strip()}\n",
    "        known_non_phy = {non_effect.strip().lower() for non_effect in non_effects_str.split(',') if non_effect.strip()}\n",
    "        \n",
    "        allowed_chunks.update(known_drugs, known_effects, known_non_phy)\n",
    "\n",
    "        # --- 5. Identify Hallucinations and Calculate Penalty ---\n",
    "        \n",
    "        # Extract noun chunks from the pre-processed response document\n",
    "        response_chunks = {\n",
    "            chunk.text.strip() for chunk in res_doc.noun_chunks \n",
    "            if chunk.text not in STOP_WORDS\n",
    "        }\n",
    "\n",
    "        hallucinated_chunks = response_chunks - allowed_chunks\n",
    "        \n",
    "        # Calculate a penalty score, capped at 1.0\n",
    "        penalty = min(1.0, 0.25 * len(hallucinated_chunks))\n",
    "        \n",
    "        rewards.append(-penalty*0.25)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433414c9-cbbc-439a-b4f6-4c719b8b9325",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "torch._dynamo.config.recompile_limit does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecompile_limit\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m  \u001b[38;5;66;03m# Default is 8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39maccumulated_recompile_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/torch/utils/_config_module.py:268\u001b[0m, in \u001b[0;36mConfigModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(name, value)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[name]\u001b[38;5;241m.\u001b[39muser_override \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: torch._dynamo.config.recompile_limit does not exist"
     ]
    }
   ],
   "source": [
    "# torch._dynamo.config.accumulated_recompile_limit = 64 #use this fot recompile error or a google search would resolve issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c755b5-d892-4d22-9df4-0f974046a313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025.6.8'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unsloth_zoo\n",
    "unsloth_zoo.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "LbmTyOtxLJhB",
   "metadata": {
    "id": "LbmTyOtxLJhB",
    "outputId": "90623bb5-802a-4102-b47a-70ae4559897b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 731 | Num Epochs = 1 | Total steps = 183\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 103,043,072 of 7,000,000,000 (1.47% trained)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 128000, 'temperature': 1e-06, 'repetition_penalty': 1.05, 'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5523432785141421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Loss: -0.05372237414121628\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1219\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n",
      "[DEBUG] Loss: -0.05372237786650658\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2438\n",
      "[DEBUG] Loss: 0.10830484330654144\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3137\n",
      "[DEBUG] Loss: 0.00022319781419355422\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='182' max='183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [182/183 52:52 < 00:17, 0.06 it/s, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / compute_reward / mean</th>\n",
       "      <th>rewards / compute_reward / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.552343</td>\n",
       "      <td>0.030738</td>\n",
       "      <td>30.375000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.375000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.061415</td>\n",
       "      <td>0.552343</td>\n",
       "      <td>0.198418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.495064</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.845102</td>\n",
       "      <td>0.495064</td>\n",
       "      <td>0.194083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.566156</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.514093</td>\n",
       "      <td>0.566156</td>\n",
       "      <td>0.166885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.669620</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.062500</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.843835</td>\n",
       "      <td>0.669620</td>\n",
       "      <td>0.142635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.763771</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.236487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.463427</td>\n",
       "      <td>0.032214</td>\n",
       "      <td>84.875000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.875000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.167487</td>\n",
       "      <td>0.463427</td>\n",
       "      <td>0.054553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.832248</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.307679</td>\n",
       "      <td>0.832248</td>\n",
       "      <td>0.054435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.495051</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>50.312500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>45.133335</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.296973</td>\n",
       "      <td>0.495051</td>\n",
       "      <td>0.262431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.727647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.543326</td>\n",
       "      <td>0.727647</td>\n",
       "      <td>0.049539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.703201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.323643</td>\n",
       "      <td>0.703201</td>\n",
       "      <td>0.128671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.537652</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>49.142860</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>0.390283</td>\n",
       "      <td>0.537652</td>\n",
       "      <td>0.246616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.588706</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>49.937500</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.937500</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.480556</td>\n",
       "      <td>0.588706</td>\n",
       "      <td>0.233271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.561157</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>39.687500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.687500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.377231</td>\n",
       "      <td>0.561157</td>\n",
       "      <td>0.230333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.485851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.734866</td>\n",
       "      <td>0.485851</td>\n",
       "      <td>0.351834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.715771</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.439068</td>\n",
       "      <td>0.715771</td>\n",
       "      <td>0.140493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.676137</td>\n",
       "      <td>0.009112</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.829212</td>\n",
       "      <td>0.676137</td>\n",
       "      <td>0.198650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.562328</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.644136</td>\n",
       "      <td>0.562328</td>\n",
       "      <td>0.067982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.602417</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>32.125000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.125000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.336030</td>\n",
       "      <td>0.602417</td>\n",
       "      <td>0.108888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.581193</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>46.937500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.937500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.583784</td>\n",
       "      <td>0.581193</td>\n",
       "      <td>0.159953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.510511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.541353</td>\n",
       "      <td>0.510511</td>\n",
       "      <td>0.125646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.724883</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>37.875000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.875000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.386246</td>\n",
       "      <td>0.724883</td>\n",
       "      <td>0.142770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.676145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.643704</td>\n",
       "      <td>0.676145</td>\n",
       "      <td>0.166493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.430431</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>26.062500</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.062500</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.803577</td>\n",
       "      <td>0.430431</td>\n",
       "      <td>0.252624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.537627</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>48.125000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.125000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.488412</td>\n",
       "      <td>0.537627</td>\n",
       "      <td>0.198158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.640202</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.611737</td>\n",
       "      <td>0.640202</td>\n",
       "      <td>0.171752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.410309</td>\n",
       "      <td>0.027862</td>\n",
       "      <td>35.625000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>29.466669</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.062813</td>\n",
       "      <td>0.410309</td>\n",
       "      <td>0.300013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.405602</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.702822</td>\n",
       "      <td>0.405602</td>\n",
       "      <td>0.109057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.457475</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>57.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>33.666668</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.518838</td>\n",
       "      <td>0.457475</td>\n",
       "      <td>0.220694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.476518</td>\n",
       "      <td>0.031655</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.664421</td>\n",
       "      <td>0.476518</td>\n",
       "      <td>0.122397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.482212</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.159543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.610520</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>50.187500</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.187500</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.560505</td>\n",
       "      <td>0.610520</td>\n",
       "      <td>0.182519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.799201</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>47.875000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.875000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.526782</td>\n",
       "      <td>0.799201</td>\n",
       "      <td>0.121417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.689803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.475842</td>\n",
       "      <td>0.689803</td>\n",
       "      <td>0.178399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.531856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40.666668</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.653052</td>\n",
       "      <td>0.531856</td>\n",
       "      <td>0.259136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>31.812500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.812500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.635633</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>0.223925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.741235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.452107</td>\n",
       "      <td>0.741235</td>\n",
       "      <td>0.143448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.739119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.687505</td>\n",
       "      <td>0.739119</td>\n",
       "      <td>0.164442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.697710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.564526</td>\n",
       "      <td>0.697710</td>\n",
       "      <td>0.205414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.666370</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>38.625000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.625000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.451748</td>\n",
       "      <td>0.666370</td>\n",
       "      <td>0.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.515398</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>42.187500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.187500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.619606</td>\n",
       "      <td>0.515398</td>\n",
       "      <td>0.243385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.636218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.689624</td>\n",
       "      <td>0.636218</td>\n",
       "      <td>0.144247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.760729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.345228</td>\n",
       "      <td>0.760729</td>\n",
       "      <td>0.087794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.287861</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>52.062500</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.062500</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.589022</td>\n",
       "      <td>0.287861</td>\n",
       "      <td>0.126392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.578985</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>35.687500</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.687500</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.611572</td>\n",
       "      <td>0.578985</td>\n",
       "      <td>0.138469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>29.937500</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.937500</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.568435</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.228663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.651174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.786835</td>\n",
       "      <td>0.651174</td>\n",
       "      <td>0.232625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.685505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.612190</td>\n",
       "      <td>0.685505</td>\n",
       "      <td>0.229959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.420943</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.633431</td>\n",
       "      <td>0.420943</td>\n",
       "      <td>0.244568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.591979</td>\n",
       "      <td>0.022909</td>\n",
       "      <td>30.937500</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.937500</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.813406</td>\n",
       "      <td>0.591979</td>\n",
       "      <td>0.148884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.645817</td>\n",
       "      <td>0.763607</td>\n",
       "      <td>0.194016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.672947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.740048</td>\n",
       "      <td>0.672947</td>\n",
       "      <td>0.170367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.678098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.549980</td>\n",
       "      <td>0.678098</td>\n",
       "      <td>0.091659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.618090</td>\n",
       "      <td>0.781438</td>\n",
       "      <td>0.138726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.582147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.094334</td>\n",
       "      <td>0.582147</td>\n",
       "      <td>0.199291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.534808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.623795</td>\n",
       "      <td>0.534808</td>\n",
       "      <td>0.140416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.587913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.733142</td>\n",
       "      <td>0.587913</td>\n",
       "      <td>0.075002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.403928</td>\n",
       "      <td>0.035876</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.209075</td>\n",
       "      <td>0.403928</td>\n",
       "      <td>0.157752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.668123</td>\n",
       "      <td>0.030323</td>\n",
       "      <td>34.437500</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.437500</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.896591</td>\n",
       "      <td>0.668123</td>\n",
       "      <td>0.206065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.476025</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>60.937500</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.937500</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.831402</td>\n",
       "      <td>0.476025</td>\n",
       "      <td>0.090237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.553438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.983834</td>\n",
       "      <td>0.553438</td>\n",
       "      <td>0.050487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.557212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.363204</td>\n",
       "      <td>0.557212</td>\n",
       "      <td>0.193195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.605755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.230321</td>\n",
       "      <td>0.605755</td>\n",
       "      <td>0.218333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.676615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.614616</td>\n",
       "      <td>0.676615</td>\n",
       "      <td>0.247548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.573011</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>19.125000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.125000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.272725</td>\n",
       "      <td>0.573011</td>\n",
       "      <td>0.177806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.757876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.740208</td>\n",
       "      <td>0.757876</td>\n",
       "      <td>0.136326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.766649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.003900</td>\n",
       "      <td>0.766649</td>\n",
       "      <td>0.122768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.734586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.900513</td>\n",
       "      <td>0.734586</td>\n",
       "      <td>0.102693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.827652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.974999</td>\n",
       "      <td>0.827652</td>\n",
       "      <td>0.076905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.869097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.061392</td>\n",
       "      <td>0.869097</td>\n",
       "      <td>0.092947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.705254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.995304</td>\n",
       "      <td>0.705254</td>\n",
       "      <td>0.159824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.717936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.041818</td>\n",
       "      <td>0.717936</td>\n",
       "      <td>0.199667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.604235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.985838</td>\n",
       "      <td>0.604235</td>\n",
       "      <td>0.155603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>33.875000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.875000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.495110</td>\n",
       "      <td>0.664207</td>\n",
       "      <td>0.120386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.646428</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>36.625000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.625000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.895924</td>\n",
       "      <td>0.646428</td>\n",
       "      <td>0.175070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.649857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.897241</td>\n",
       "      <td>0.649857</td>\n",
       "      <td>0.106060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.622510</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>34.062500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.062500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.924962</td>\n",
       "      <td>0.622510</td>\n",
       "      <td>0.165936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.726094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.536793</td>\n",
       "      <td>0.726094</td>\n",
       "      <td>0.115764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.488289</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.774625</td>\n",
       "      <td>0.488289</td>\n",
       "      <td>0.353983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.784291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.092675</td>\n",
       "      <td>0.784291</td>\n",
       "      <td>0.152404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>34.125000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.125000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.391835</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>0.183106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.747679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.453942</td>\n",
       "      <td>0.747679</td>\n",
       "      <td>0.082334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.592024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.247514</td>\n",
       "      <td>0.592024</td>\n",
       "      <td>0.236082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.768523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.685174</td>\n",
       "      <td>0.768523</td>\n",
       "      <td>0.145733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>40.875000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.875000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.880130</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.183397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.664060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.049935</td>\n",
       "      <td>0.664060</td>\n",
       "      <td>0.235954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.766644</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>36.312500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.312500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.988644</td>\n",
       "      <td>0.766644</td>\n",
       "      <td>0.101817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.622299</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>32.312500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.312500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.684655</td>\n",
       "      <td>0.622299</td>\n",
       "      <td>0.090363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.773471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.457706</td>\n",
       "      <td>0.773471</td>\n",
       "      <td>0.073345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.701410</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>32.125000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.125000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.139737</td>\n",
       "      <td>0.701410</td>\n",
       "      <td>0.132921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.684265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.751803</td>\n",
       "      <td>0.684265</td>\n",
       "      <td>0.177943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.549769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.794380</td>\n",
       "      <td>0.549769</td>\n",
       "      <td>0.137604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.660074</td>\n",
       "      <td>0.007912</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.675086</td>\n",
       "      <td>0.660074</td>\n",
       "      <td>0.192714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.774433</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.875000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.774433</td>\n",
       "      <td>0.021668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.614389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.449408</td>\n",
       "      <td>0.614389</td>\n",
       "      <td>0.071124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.843783</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.181122</td>\n",
       "      <td>0.843783</td>\n",
       "      <td>0.100839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.722749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.864440</td>\n",
       "      <td>0.722749</td>\n",
       "      <td>0.155822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.409372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.926867</td>\n",
       "      <td>0.409372</td>\n",
       "      <td>0.076377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.600971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.161230</td>\n",
       "      <td>0.600971</td>\n",
       "      <td>0.152597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.422699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.107070</td>\n",
       "      <td>0.422699</td>\n",
       "      <td>0.180695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.671677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.851962</td>\n",
       "      <td>0.671677</td>\n",
       "      <td>0.294069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.495708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.064052</td>\n",
       "      <td>0.495708</td>\n",
       "      <td>0.185181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.719961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.171562</td>\n",
       "      <td>0.719961</td>\n",
       "      <td>0.183496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.750589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.744568</td>\n",
       "      <td>0.750589</td>\n",
       "      <td>0.090352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.664105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0.664105</td>\n",
       "      <td>0.183087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.503277</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>32.687500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.687500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.631060</td>\n",
       "      <td>0.503277</td>\n",
       "      <td>0.161273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.554026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.245805</td>\n",
       "      <td>0.554026</td>\n",
       "      <td>0.170404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.619805</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.078451</td>\n",
       "      <td>0.619805</td>\n",
       "      <td>0.092974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.639743</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>28.375000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.375000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.410015</td>\n",
       "      <td>0.639743</td>\n",
       "      <td>0.090056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.667172</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>33.812500</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.812500</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.178359</td>\n",
       "      <td>0.667172</td>\n",
       "      <td>0.156487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.577387</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>42.625000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.625000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.577387</td>\n",
       "      <td>0.233904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.674644</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>26.437500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.437500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.490822</td>\n",
       "      <td>0.674644</td>\n",
       "      <td>0.276723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.623720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>39.333336</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.529459</td>\n",
       "      <td>0.623720</td>\n",
       "      <td>0.255155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.592236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.948537</td>\n",
       "      <td>0.592236</td>\n",
       "      <td>0.217687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.628741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.612068</td>\n",
       "      <td>0.628741</td>\n",
       "      <td>0.234610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.645863</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>30.875000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.875000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.337103</td>\n",
       "      <td>0.645863</td>\n",
       "      <td>0.163551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.760173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.328754</td>\n",
       "      <td>0.760173</td>\n",
       "      <td>0.179443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.656995</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>0.169409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.875000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.875000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.028534</td>\n",
       "      <td>0.593990</td>\n",
       "      <td>0.149818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.631028</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.388850</td>\n",
       "      <td>0.631028</td>\n",
       "      <td>0.085893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.570726</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.875000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.446955</td>\n",
       "      <td>0.570726</td>\n",
       "      <td>0.134220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.778564</td>\n",
       "      <td>0.020339</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.602953</td>\n",
       "      <td>0.778564</td>\n",
       "      <td>0.154424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.767460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.919915</td>\n",
       "      <td>0.767460</td>\n",
       "      <td>0.103191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.761166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.161535</td>\n",
       "      <td>0.761166</td>\n",
       "      <td>0.074092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.534714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.271673</td>\n",
       "      <td>0.534714</td>\n",
       "      <td>0.206280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.663130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.764276</td>\n",
       "      <td>0.663130</td>\n",
       "      <td>0.112375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.616208</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>31.687500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.687500</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.160337</td>\n",
       "      <td>0.616208</td>\n",
       "      <td>0.116702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.710530</td>\n",
       "      <td>0.025856</td>\n",
       "      <td>44.937500</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.937500</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.564818</td>\n",
       "      <td>0.710530</td>\n",
       "      <td>0.185037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.688894</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.617885</td>\n",
       "      <td>0.688894</td>\n",
       "      <td>0.109789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.626845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.146792</td>\n",
       "      <td>0.626845</td>\n",
       "      <td>0.090130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.752794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.901947</td>\n",
       "      <td>0.752794</td>\n",
       "      <td>0.071255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.432483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.577957</td>\n",
       "      <td>0.432483</td>\n",
       "      <td>0.223113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.615660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.833574</td>\n",
       "      <td>0.615660</td>\n",
       "      <td>0.195508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.545780</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>28.437500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.437500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.937667</td>\n",
       "      <td>0.545780</td>\n",
       "      <td>0.139998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.741765</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>31.062500</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.062500</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.186133</td>\n",
       "      <td>0.741765</td>\n",
       "      <td>0.159325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.712992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.090269</td>\n",
       "      <td>0.712992</td>\n",
       "      <td>0.161172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.586700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.706695</td>\n",
       "      <td>0.586700</td>\n",
       "      <td>0.109291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.681756</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>0.496834</td>\n",
       "      <td>0.681756</td>\n",
       "      <td>0.226059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.636726</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.567980</td>\n",
       "      <td>0.636726</td>\n",
       "      <td>0.146973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.714461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.901513</td>\n",
       "      <td>0.714461</td>\n",
       "      <td>0.127266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.623197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.017332</td>\n",
       "      <td>0.623197</td>\n",
       "      <td>0.258655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.707896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.682627</td>\n",
       "      <td>0.707896</td>\n",
       "      <td>0.267859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.663478</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>0.663478</td>\n",
       "      <td>0.051129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.803643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.678699</td>\n",
       "      <td>0.803643</td>\n",
       "      <td>0.101566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.675086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.025971</td>\n",
       "      <td>0.675086</td>\n",
       "      <td>0.159786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.767025</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>34.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.923057</td>\n",
       "      <td>0.767025</td>\n",
       "      <td>0.093152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.714177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.785474</td>\n",
       "      <td>0.714177</td>\n",
       "      <td>0.332185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.923379</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>0.200779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>37.375000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.375000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.929858</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.070075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.679511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.363641</td>\n",
       "      <td>0.679511</td>\n",
       "      <td>0.248558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.629854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.429978</td>\n",
       "      <td>0.629854</td>\n",
       "      <td>0.207712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.616206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.112409</td>\n",
       "      <td>0.616206</td>\n",
       "      <td>0.196405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.689473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.038050</td>\n",
       "      <td>0.689473</td>\n",
       "      <td>0.149608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.636734</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>29.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.937500</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.190066</td>\n",
       "      <td>0.636734</td>\n",
       "      <td>0.186409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.525438</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>23.937500</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.937500</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.070934</td>\n",
       "      <td>0.525438</td>\n",
       "      <td>0.195803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.824861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.059619</td>\n",
       "      <td>0.824861</td>\n",
       "      <td>0.100146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.562591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.862647</td>\n",
       "      <td>0.562591</td>\n",
       "      <td>0.183966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.522174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.476701</td>\n",
       "      <td>0.522174</td>\n",
       "      <td>0.179398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.602189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.819497</td>\n",
       "      <td>0.602189</td>\n",
       "      <td>0.279893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.738227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.570848</td>\n",
       "      <td>0.738227</td>\n",
       "      <td>0.066087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.890246</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.190489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.617782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.218955</td>\n",
       "      <td>0.617782</td>\n",
       "      <td>0.158079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.668618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.818190</td>\n",
       "      <td>0.668618</td>\n",
       "      <td>0.114603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.654040</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>30.937500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.937500</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.564997</td>\n",
       "      <td>0.654040</td>\n",
       "      <td>0.208772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.753123</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.125000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.026927</td>\n",
       "      <td>0.753123</td>\n",
       "      <td>0.186657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.740727</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>42.687500</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.687500</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.857824</td>\n",
       "      <td>0.740727</td>\n",
       "      <td>0.241687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.718808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.656582</td>\n",
       "      <td>0.718808</td>\n",
       "      <td>0.076849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.403811</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.641820</td>\n",
       "      <td>0.403811</td>\n",
       "      <td>0.129499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.648998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.987917</td>\n",
       "      <td>0.648998</td>\n",
       "      <td>0.077274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.842190</td>\n",
       "      <td>0.830627</td>\n",
       "      <td>0.299381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.578372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.456504</td>\n",
       "      <td>0.578372</td>\n",
       "      <td>0.159460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.781855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.751570</td>\n",
       "      <td>0.781855</td>\n",
       "      <td>0.133412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.768370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.380333</td>\n",
       "      <td>0.768370</td>\n",
       "      <td>0.160995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.609045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1.237231</td>\n",
       "      <td>0.609045</td>\n",
       "      <td>0.175363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.619309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.525901</td>\n",
       "      <td>0.619309</td>\n",
       "      <td>0.210010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.738911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.142931</td>\n",
       "      <td>0.738911</td>\n",
       "      <td>0.185679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.580369</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.639276</td>\n",
       "      <td>0.580369</td>\n",
       "      <td>0.175103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.503881</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>46.875000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.875000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.700232</td>\n",
       "      <td>0.503881</td>\n",
       "      <td>0.109037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.479569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.552146</td>\n",
       "      <td>0.479569</td>\n",
       "      <td>0.151672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>42.875000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.875000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.756917</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.258388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.720684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.983879</td>\n",
       "      <td>0.720684</td>\n",
       "      <td>0.032277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.645919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.701001</td>\n",
       "      <td>0.645919</td>\n",
       "      <td>0.093481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.651533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.973612</td>\n",
       "      <td>0.651533</td>\n",
       "      <td>0.235810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4950642073804694\n",
      "[DEBUG] Loss: 0.06253045797348022\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1905\n",
      "[DEBUG] Loss: 0.0002712442073971033\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1905\n",
      "[DEBUG] Loss: -0.06224590167403221\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2023\n",
      "[DEBUG] Loss: 0.0002860786335077137\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5661556733163337\n",
      "[DEBUG] Loss: 0.03123360499739647\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0620\n",
      "[DEBUG] Loss: -0.031045246869325638\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0326\n",
      "[DEBUG] Loss: 0.027052082121372223\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3083\n",
      "[DEBUG] Loss: -0.02671671286225319\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.5764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6696199793536061\n",
      "[DEBUG] Loss: 0.031392209231853485\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0735\n",
      "[DEBUG] Loss: 0.0002819339861162007\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0735\n",
      "[DEBUG] Loss: -0.06220267340540886\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1077\n",
      "[DEBUG] Loss: 0.0313643254339695\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.35318255569791296\n",
      "[DEBUG] Loss: 0.00014639346045441926\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0002563924062997103\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0001829674729378894\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00029296643333509564\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.46342718800801685\n",
      "[DEBUG] Loss: -0.031977832317352295\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1823\n",
      "[DEBUG] Loss: -0.08417302370071411\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2553\n",
      "[DEBUG] Loss: 0.14831358194351196\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.5132\n",
      "[DEBUG] Loss: -0.03197765722870827\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.8322477824193442\n",
      "[DEBUG] Loss: 0.00015733018517494202\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1527\n",
      "[DEBUG] Loss: 0.0001026354730129242\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3028\n",
      "[DEBUG] Loss: 4.414909199113026e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3029\n",
      "[DEBUG] Loss: 4.2527259211055934e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.49505093446838505\n",
      "[DEBUG] Loss: -0.03240238130092621\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0796\n",
      "[DEBUG] Loss: -0.04410041868686676\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1893\n",
      "[DEBUG] Loss: 0.045706938952207565\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2407\n",
      "[DEBUG] Loss: 0.031041251495480537\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7276468555073562\n",
      "[DEBUG] Loss: 6.870881770737469e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n",
      "[DEBUG] Loss: 0.00021760951494798064\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.0001431591808795929\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0027\n",
      "[DEBUG] Loss: 0.0001431591808795929\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7032014577818131\n",
      "[DEBUG] Loss: 3.677861241158098e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 9.629111445974559e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.00014209173968993127\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0035\n",
      "[DEBUG] Loss: 8.257923764176667e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5376520193450476\n",
      "[DEBUG] Loss: 0.00011964501754846424\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.040871597826480865\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0944\n",
      "[DEBUG] Loss: 0.00013469532132148743\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1165\n",
      "[DEBUG] Loss: -0.04061734303832054\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5887057218470201\n",
      "[DEBUG] Loss: 0.054034482687711716\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1222\n",
      "[DEBUG] Loss: -0.05361918359994888\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0986\n",
      "[DEBUG] Loss: -0.053838398307561874\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1648\n",
      "[DEBUG] Loss: 0.05403650552034378\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5611567216696133\n",
      "[DEBUG] Loss: 0.09374095499515533\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3784\n",
      "[DEBUG] Loss: -0.031116455793380737\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3643\n",
      "[DEBUG] Loss: -0.03108999878168106\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3748\n",
      "[DEBUG] Loss: -0.03114425018429756\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4858510614234774\n",
      "[DEBUG] Loss: 0.0002034102799370885\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00015294669719878584\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.0002556758117862046\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00020160837448202074\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7157708426960507\n",
      "[DEBUG] Loss: 7.181209366535768e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.05417322367429733\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.5660\n",
      "[DEBUG] Loss: 0.0002037733793258667\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.6016\n",
      "[DEBUG] Loss: -0.05395890399813652\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6761366732026549\n",
      "[DEBUG] Loss: 0.00027112168027088046\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.05416657775640488\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2220\n",
      "[DEBUG] Loss: -0.05383545160293579\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3448\n",
      "[DEBUG] Loss: 0.00040717102820053697\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5623279995708009\n",
      "[DEBUG] Loss: 0.08066160976886749\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3371\n",
      "[DEBUG] Loss: 0.09143376350402832\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.5855\n",
      "[DEBUG] Loss: 0.035795483738183975\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.5705\n",
      "[DEBUG] Loss: -0.20716100931167603\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6024173692301256\n",
      "[DEBUG] Loss: -0.05390141159296036\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1146\n",
      "[DEBUG] Loss: 9.407324250787497e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1147\n",
      "[DEBUG] Loss: -0.05393612012267113\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2292\n",
      "[DEBUG] Loss: 0.10810703039169312\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5811931565527326\n",
      "[DEBUG] Loss: 0.00021790340542793274\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0759\n",
      "[DEBUG] Loss: -0.01941642165184021\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2437\n",
      "[DEBUG] Loss: 0.08215201646089554\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1949\n",
      "[DEBUG] Loss: -0.062305547297000885\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5105111374416814\n",
      "[DEBUG] Loss: 4.7337885916931555e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0001426129456376657\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00018124260532204062\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00017990541527979076\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7248833141719674\n",
      "[DEBUG] Loss: -0.06224364787340164\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0825\n",
      "[DEBUG] Loss: -0.031080402433872223\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1238\n",
      "[DEBUG] Loss: 0.09362338483333588\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1068\n",
      "[DEBUG] Loss: 0.00011709942191373557\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6761450510390377\n",
      "[DEBUG] Loss: 0.00026463117683306336\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.0003316676593385637\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0025\n",
      "[DEBUG] Loss: 1.7961274352273904e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0025\n",
      "[DEBUG] Loss: 0.00010020204354077578\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.43043082870821714\n",
      "[DEBUG] Loss: -0.058678142726421356\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1173\n",
      "[DEBUG] Loss: 0.00024150684475898743\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1172\n",
      "[DEBUG] Loss: 0.08848826587200165\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1014\n",
      "[DEBUG] Loss: -0.029196301475167274\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.537626492471865\n",
      "[DEBUG] Loss: 0.054057519882917404\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1495\n",
      "[DEBUG] Loss: 0.00013389630476012826\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1495\n",
      "[DEBUG] Loss: -0.10772071778774261\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1684\n",
      "[DEBUG] Loss: 0.05402493476867676\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6402016571915148\n",
      "[DEBUG] Loss: -0.05388360470533371\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2465\n",
      "[DEBUG] Loss: 0.00017877864593174309\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2465\n",
      "[DEBUG] Loss: 0.10809653997421265\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2677\n",
      "[DEBUG] Loss: -0.05364521965384483\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.41030948386079963\n",
      "[DEBUG] Loss: 0.0001875800226116553\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.03255951404571533\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0838\n",
      "[DEBUG] Loss: -0.09306633472442627\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4897\n",
      "[DEBUG] Loss: 0.062051381915807724\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.40560236708252484\n",
      "[DEBUG] Loss: -0.045454394072294235\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0835\n",
      "[DEBUG] Loss: 0.045679591596126556\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0799\n",
      "[DEBUG] Loss: 0.0003847554326057434\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1724\n",
      "[DEBUG] Loss: 0.0002510308404453099\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4574751956321491\n",
      "[DEBUG] Loss: 0.00013096354086883366\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1296\n",
      "[DEBUG] Loss: 4.697749318438582e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1296\n",
      "[DEBUG] Loss: 0.0001589233725098893\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1296\n",
      "[DEBUG] Loss: 0.00016680359840393066\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.47651836966711697\n",
      "[DEBUG] Loss: 0.012199527584016323\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0194\n",
      "[DEBUG] Loss: 0.03598291426897049\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1516\n",
      "[DEBUG] Loss: 0.000329246191540733\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1516\n",
      "[DEBUG] Loss: -0.04765472933650017\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7280699954292394\n",
      "[DEBUG] Loss: 0.00017004928668029606\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 9.633722947910428e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00011221627937629819\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00012620093184523284\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6105204521980118\n",
      "[DEBUG] Loss: 0.062290653586387634\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1459\n",
      "[DEBUG] Loss: 0.031238367781043053\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2184\n",
      "[DEBUG] Loss: -0.09315565973520279\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0592\n",
      "[DEBUG] Loss: 0.00018334870401304215\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7992008428033409\n",
      "[DEBUG] Loss: 0.031218955293297768\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0212\n",
      "[DEBUG] Loss: 0.0002902965643443167\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0213\n",
      "[DEBUG] Loss: 0.0622081533074379\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0637\n",
      "[DEBUG] Loss: -0.09297741204500198\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6898025963888047\n",
      "[DEBUG] Loss: 0.00031856884015724063\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 8.423474355367944e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 5.183177927392535e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00015669898129999638\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5318559964344208\n",
      "[DEBUG] Loss: 0.0001378469169139862\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.000162822354468517\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00021390660549513996\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0001607510057510808\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.644899533331126\n",
      "[DEBUG] Loss: 0.08455127477645874\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2019\n",
      "[DEBUG] Loss: -0.19893532991409302\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2833\n",
      "[DEBUG] Loss: 0.05425635352730751\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2558\n",
      "[DEBUG] Loss: 0.06085056811571121\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7412349141970883\n",
      "[DEBUG] Loss: 8.045992581173778e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00012374945799820125\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00014971537166275084\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 0.00014107307652011514\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7391193266934803\n",
      "[DEBUG] Loss: 0.0001575031055836007\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00017323356587439775\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 0.00019093012087978423\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0038\n",
      "[DEBUG] Loss: 0.00017519966058898717\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6977100063777741\n",
      "[DEBUG] Loss: 0.00013739531277678907\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00016143720131367445\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00010080427455250174\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0026\n",
      "[DEBUG] Loss: 0.00023290117678698152\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6663695337465405\n",
      "[DEBUG] Loss: 0.054038338363170624\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1666\n",
      "[DEBUG] Loss: -0.10748709738254547\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1932\n",
      "[DEBUG] Loss: 0.053905632346868515\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1107\n",
      "[DEBUG] Loss: 0.00014151431969366968\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5153977318212035\n",
      "[DEBUG] Loss: 0.05401182919740677\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0980\n",
      "[DEBUG] Loss: -0.06155206635594368\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1121\n",
      "[DEBUG] Loss: 0.14646832644939423\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2088\n",
      "[DEBUG] Loss: -0.13828854262828827\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6362177309132817\n",
      "[DEBUG] Loss: 0.00020079022215213627\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00018875193200074136\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00016891116683837026\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0035\n",
      "[DEBUG] Loss: 0.00011350265413057059\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7607293203289167\n",
      "[DEBUG] Loss: 6.466412742156535e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.00011481995170470327\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 6.082573963794857e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0021\n",
      "[DEBUG] Loss: 0.00011865833948832005\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.2878611418388822\n",
      "[DEBUG] Loss: -0.03883788362145424\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0743\n",
      "[DEBUG] Loss: 0.137412890791893\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2855\n",
      "[DEBUG] Loss: -0.010391244664788246\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2391\n",
      "[DEBUG] Loss: -0.08755045384168625\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5789851361878147\n",
      "[DEBUG] Loss: -0.09337328374385834\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1546\n",
      "[DEBUG] Loss: 0.00018346431897953153\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1546\n",
      "[DEBUG] Loss: 0.09360988438129425\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1368\n",
      "[DEBUG] Loss: 0.00018941763846669346\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5422001537491804\n",
      "[DEBUG] Loss: -0.03075227700173855\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2634\n",
      "[DEBUG] Loss: 0.00013339120778255165\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2635\n",
      "[DEBUG] Loss: 0.06201447546482086\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3230\n",
      "[DEBUG] Loss: -0.030743341892957687\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6511741159057186\n",
      "[DEBUG] Loss: 0.0002660092432051897\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00015461115981452167\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00018103927141055465\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0002269844408147037\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6855053790940655\n",
      "[DEBUG] Loss: 0.00021692566224373877\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00016397751460317522\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0001642097340663895\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.00011172602535225451\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4209425518456959\n",
      "[DEBUG] Loss: 0.0001694544916972518\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00019277632236480713\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0847\n",
      "[DEBUG] Loss: 0.00015164539217948914\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1694\n",
      "[DEBUG] Loss: 0.00021187537640798837\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5919791807304662\n",
      "[DEBUG] Loss: 0.07111000269651413\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3048\n",
      "[DEBUG] Loss: -0.04797286540269852\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.5464\n",
      "[DEBUG] Loss: 0.03153214976191521\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.8443\n",
      "[DEBUG] Loss: -0.053741104900836945\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.763606833257553\n",
      "[DEBUG] Loss: 0.00022264296421781182\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.00018944311887025833\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00016772348317317665\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 9.108435187954456e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6729472340883658\n",
      "[DEBUG] Loss: 0.00019573772442527115\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00017082085832953453\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0021\n",
      "[DEBUG] Loss: 0.00016487186076119542\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0025\n",
      "[DEBUG] Loss: 0.00025152048328891397\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6780975469867295\n",
      "[DEBUG] Loss: 0.000125444756122306\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.00016991887241601944\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00017502001719549298\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.00015702070959378034\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7814380461095517\n",
      "[DEBUG] Loss: 0.00014050355821382254\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0001880222698673606\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.0001757362624630332\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 5.7752135035116225e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5821473946542511\n",
      "[DEBUG] Loss: 0.00043679928057827055\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00030619429890066385\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 0.0003150701231788844\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0030\n",
      "[DEBUG] Loss: 0.0001667134347371757\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5348076658989441\n",
      "[DEBUG] Loss: 0.00021569986711256206\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 5.0886159442598e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0001803749182727188\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.00023241553572006524\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5879128226972037\n",
      "[DEBUG] Loss: 0.00022548541892319918\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0002012894256040454\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.00013530108844861388\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00024308176944032311\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.40392754884783205\n",
      "[DEBUG] Loss: 0.06318788230419159\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 118.4412\n",
      "[DEBUG] Loss: -0.031033620238304138\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 118.6390\n",
      "[DEBUG] Loss: -0.03083798661828041\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 118.8359\n",
      "[DEBUG] Loss: 0.0003549371031112969\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 118.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6681224880770936\n",
      "[DEBUG] Loss: 0.039489615708589554\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4113\n",
      "[DEBUG] Loss: 0.029921038076281548\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3189\n",
      "[DEBUG] Loss: -0.037626445293426514\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.6461\n",
      "[DEBUG] Loss: -0.030810583382844925\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.6499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4760247780784729\n",
      "[DEBUG] Loss: 0.07637239247560501\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1492\n",
      "[DEBUG] Loss: 0.0004061562358401716\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1494\n",
      "[DEBUG] Loss: 0.0021927705965936184\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1528\n",
      "[DEBUG] Loss: -0.07794279605150223\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5534383050554276\n",
      "[DEBUG] Loss: 0.0002611122326925397\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0003847216139547527\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00017597862461116165\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00043907546205446124\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5572121097389677\n",
      "[DEBUG] Loss: 0.00043730728793889284\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.0002457736700307578\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.00026143190916627645\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0020\n",
      "[DEBUG] Loss: 0.0004529655270744115\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6057552476852546\n",
      "[DEBUG] Loss: 0.0003239299694541842\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.0006182804354466498\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.00020861449593212456\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.0002888083690777421\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6766148929491015\n",
      "[DEBUG] Loss: 0.00018523466133046895\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00014543283032253385\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0001902584044728428\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00024092460807878524\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5730109062141729\n",
      "[DEBUG] Loss: 0.05441349372267723\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3510\n",
      "[DEBUG] Loss: -0.053736429661512375\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1169\n",
      "[DEBUG] Loss: -0.05354895815253258\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4373\n",
      "[DEBUG] Loss: 0.05422602593898773\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7578756524752309\n",
      "[DEBUG] Loss: 0.00014401118096429855\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.000201971604838036\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0001244591985596344\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00035140325780957937\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7666489023183274\n",
      "[DEBUG] Loss: 0.00014890500460751355\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.00030059152049943805\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0002492578641977161\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.0004009443800896406\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7345856401580084\n",
      "[DEBUG] Loss: 0.0003030701191164553\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 6.27355111646466e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 0.00025841500610113144\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0046\n",
      "[DEBUG] Loss: 0.0004094394389539957\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.8276523666875277\n",
      "[DEBUG] Loss: 0.0002682069898582995\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0003885259502567351\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00019834180420730263\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0003186608082614839\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.8690972210438214\n",
      "[DEBUG] Loss: 0.00028688402380794287\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0002503504219930619\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.0003234175965189934\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0025\n",
      "[DEBUG] Loss: 0.00028688402380794287\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7052544501505322\n",
      "[DEBUG] Loss: 0.0003390662313904613\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.000176036570337601\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00021870876662433147\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n",
      "[DEBUG] Loss: 0.0003646129625849426\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.717936427336387\n",
      "[DEBUG] Loss: 0.000361109443474561\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00018110396922565997\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00030648941174149513\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00029112130869179964\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6042353500623043\n",
      "[DEBUG] Loss: 0.0003875830734614283\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00027910774224437773\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00027827531448565423\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0021\n",
      "[DEBUG] Loss: 0.00016979995416477323\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6642073258100075\n",
      "[DEBUG] Loss: 0.0001554464251967147\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.031218452379107475\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0267\n",
      "[DEBUG] Loss: -0.06214078888297081\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1114\n",
      "[DEBUG] Loss: 0.03125505521893501\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6464277786158728\n",
      "[DEBUG] Loss: -0.05931984633207321\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0633\n",
      "[DEBUG] Loss: 0.0897500216960907\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0643\n",
      "[DEBUG] Loss: -0.029548175632953644\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0699\n",
      "[DEBUG] Loss: 0.00022012430417817086\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6498573443725956\n",
      "[DEBUG] Loss: 0.0003076972789131105\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00027471460634842515\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.00013876165030524135\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.00037768486072309315\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6225099560358621\n",
      "[DEBUG] Loss: 0.06140846386551857\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 3.4641\n",
      "[DEBUG] Loss: 9.611910354578868e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 3.4637\n",
      "[DEBUG] Loss: -0.0608646497130394\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3332\n",
      "[DEBUG] Loss: 0.0003806851163972169\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7260939051140711\n",
      "[DEBUG] Loss: 0.000134821399115026\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0002533082151785493\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.00021964855841360986\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00040545471711084247\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4882888597648778\n",
      "[DEBUG] Loss: -0.022709347307682037\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2739\n",
      "[DEBUG] Loss: 0.003207571804523468\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2809\n",
      "[DEBUG] Loss: -0.04588799923658371\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3003\n",
      "[DEBUG] Loss: 0.06654760986566544\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7842907758807818\n",
      "[DEBUG] Loss: 0.0002868660376407206\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.00043577596079558134\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00038538160151802003\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.00038538160151802003\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6519778217158836\n",
      "[DEBUG] Loss: 0.05439790338277817\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1774\n",
      "[DEBUG] Loss: -0.053716424852609634\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0962\n",
      "[DEBUG] Loss: -0.053658194839954376\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1532\n",
      "[DEBUG] Loss: 0.05445367842912674\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.747678739208831\n",
      "[DEBUG] Loss: 0.0001338583679171279\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 0.00017554682563059032\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0042\n",
      "[DEBUG] Loss: 0.00013379140000324696\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0071\n",
      "[DEBUG] Loss: 9.55879149842076e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5920242350741138\n",
      "[DEBUG] Loss: 0.0005032572080381215\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00042919476982206106\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00025679200189188123\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00033085444010794163\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7685234311556512\n",
      "[DEBUG] Loss: 0.00022710034681949764\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0001468694827053696\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00015750288730487227\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0002377337368670851\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6889001424347441\n",
      "[DEBUG] Loss: 0.00016695083468221128\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.042468275874853134\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4172\n",
      "[DEBUG] Loss: -0.08691410720348358\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 1.0967\n",
      "[DEBUG] Loss: 0.04522213339805603\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6640603891393062\n",
      "[DEBUG] Loss: 0.000211496400879696\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00034173973836004734\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.0004604454734362662\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.0001381171605316922\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7666440639694702\n",
      "[DEBUG] Loss: -0.07881192117929459\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0522\n",
      "[DEBUG] Loss: 0.07918831706047058\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0439\n",
      "[DEBUG] Loss: 0.0003678005887195468\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0439\n",
      "[DEBUG] Loss: 0.0004469890263862908\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6222992140715767\n",
      "[DEBUG] Loss: 0.06251788884401321\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2317\n",
      "[DEBUG] Loss: -0.09327177703380585\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1606\n",
      "[DEBUG] Loss: 0.031329356133937836\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1128\n",
      "[DEBUG] Loss: 0.0001408636017004028\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7734709377892497\n",
      "[DEBUG] Loss: 0.000489204132463783\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0005242438055574894\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00039739886415190995\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.0006861283909529448\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7014101813209792\n",
      "[DEBUG] Loss: 0.054002758115530014\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1523\n",
      "[DEBUG] Loss: 0.00035238638520240784\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1428\n",
      "[DEBUG] Loss: 0.00022763390734326094\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1428\n",
      "[DEBUG] Loss: -0.05342213809490204\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6842648703951113\n",
      "[DEBUG] Loss: 0.00034009222872555256\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00036479069967754185\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00033842315315268934\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0016\n",
      "[DEBUG] Loss: 0.00034776871325448155\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5497688428321167\n",
      "[DEBUG] Loss: 0.0004727678024210036\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0004575424827635288\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0019\n",
      "[DEBUG] Loss: 0.0006111285765655339\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0027\n",
      "[DEBUG] Loss: 0.0003496322897262871\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6600736328374037\n",
      "[DEBUG] Loss: 9.937580034602433e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.05426570400595665\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3863\n",
      "[DEBUG] Loss: -0.05376489460468292\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2650\n",
      "[DEBUG] Loss: 0.00013686639431398362\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7744326846761806\n",
      "[DEBUG] Loss: 0.0005514949443750083\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: -0.031066102907061577\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0810\n",
      "[DEBUG] Loss: -0.03090609982609749\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1620\n",
      "[DEBUG] Loss: 0.06252498924732208\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6143886631701303\n",
      "[DEBUG] Loss: 0.0003923462354578078\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0002153584355255589\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0004112143942620605\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0005504658329300582\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.8437828428874926\n",
      "[DEBUG] Loss: -0.06193024292588234\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.7623\n",
      "[DEBUG] Loss: 0.06264186650514603\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 1.0068\n",
      "[DEBUG] Loss: 0.00032774702413007617\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 1.0068\n",
      "[DEBUG] Loss: 0.0002447720034979284\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 1.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7227492633820225\n",
      "[DEBUG] Loss: 0.00023279074230231345\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00030483532464131713\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 7.628308230778202e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.0003172538126818836\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4093719141980716\n",
      "[DEBUG] Loss: 0.00023952650371938944\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.0003257159551139921\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0022\n",
      "[DEBUG] Loss: 0.00032991947955451906\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0024\n",
      "[DEBUG] Loss: 0.0004077018238604069\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6009712072439385\n",
      "[DEBUG] Loss: 0.0004005256050731987\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 9.590551781002432e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00047323788749054074\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.0002543239970691502\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4226986949019406\n",
      "[DEBUG] Loss: 0.0005739213083870709\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0005592077504843473\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.000581182655878365\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.0005519463447853923\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6716773934673711\n",
      "[DEBUG] Loss: 0.00033975677797570825\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.00016697299724910408\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00028634420596063137\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.0002664447238203138\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4957082389194468\n",
      "[DEBUG] Loss: 0.00038536370266228914\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.00022292208450380713\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.0005478388047777116\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0032\n",
      "[DEBUG] Loss: 0.00038536370266228914\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7199611150621013\n",
      "[DEBUG] Loss: 0.0003817748511210084\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.00018854386871680617\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0027\n",
      "[DEBUG] Loss: 0.00045609139488078654\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0036\n",
      "[DEBUG] Loss: 0.00026286044158041477\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7505894165304082\n",
      "[DEBUG] Loss: 0.00024538030265830457\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0028\n",
      "[DEBUG] Loss: 0.0002074755320791155\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0056\n",
      "[DEBUG] Loss: 0.00016586476704105735\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0084\n",
      "[DEBUG] Loss: 0.00036280066706240177\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.664105401131551\n",
      "[DEBUG] Loss: 8.672836702317e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0003269869484938681\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00010718370322138071\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00028008053777739406\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5032768226674362\n",
      "[DEBUG] Loss: 0.0860111340880394\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1089\n",
      "[DEBUG] Loss: 0.00025367882335558534\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1089\n",
      "[DEBUG] Loss: -0.08675023913383484\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0708\n",
      "[DEBUG] Loss: 0.0013044270453974605\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5540258375391978\n",
      "[DEBUG] Loss: 0.0004281005240045488\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00046426214976236224\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.0003055112319998443\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00026934960624203086\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6198045756022764\n",
      "[DEBUG] Loss: 0.06290080398321152\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2161\n",
      "[DEBUG] Loss: -0.061292413622140884\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1705\n",
      "[DEBUG] Loss: 0.00044140356476418674\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1704\n",
      "[DEBUG] Loss: 0.00036474043736234307\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6397432824995345\n",
      "[DEBUG] Loss: 0.0004671632486861199\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: -0.05299615487456322\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0822\n",
      "[DEBUG] Loss: 0.0005556955584324896\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0822\n",
      "[DEBUG] Loss: 0.053634919226169586\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6671722789010981\n",
      "[DEBUG] Loss: -0.011863574385643005\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0632\n",
      "[DEBUG] Loss: 0.15071900188922882\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1940\n",
      "[DEBUG] Loss: -0.11923986673355103\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1977\n",
      "[DEBUG] Loss: -0.018439294770359993\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5773869158318039\n",
      "[DEBUG] Loss: -0.057692695409059525\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1874\n",
      "[DEBUG] Loss: 0.06250818818807602\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2031\n",
      "[DEBUG] Loss: 0.00033118732972070575\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2031\n",
      "[DEBUG] Loss: -0.004275084473192692\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6746444324701273\n",
      "[DEBUG] Loss: 0.0001828472304623574\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: -0.03069002740085125\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0873\n",
      "[DEBUG] Loss: 0.06258398294448853\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1595\n",
      "[DEBUG] Loss: -0.030444853007793427\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6237203931276726\n",
      "[DEBUG] Loss: 0.00015809762408025563\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0001692624355200678\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0019\n",
      "[DEBUG] Loss: 0.0001266901526832953\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0024\n",
      "[DEBUG] Loss: 0.00013448370737023652\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5922356000981712\n",
      "[DEBUG] Loss: 0.0003583739744499326\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.00030310882721096277\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.0002885622379835695\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.00026239032740704715\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6287408480668593\n",
      "[DEBUG] Loss: 0.0002845189010258764\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0002845189010258764\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.0005575231043621898\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0005643661133944988\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6458626434118802\n",
      "[DEBUG] Loss: 0.09319251030683517\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0410\n",
      "[DEBUG] Loss: -0.030203672125935555\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0536\n",
      "[DEBUG] Loss: -0.030439317226409912\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0694\n",
      "[DEBUG] Loss: -0.030323024839162827\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7601725848728447\n",
      "[DEBUG] Loss: 0.0008899745298549533\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0015\n",
      "[DEBUG] Loss: 0.00040293848724104464\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0020\n",
      "[DEBUG] Loss: 0.0006922176107764244\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0036\n",
      "[DEBUG] Loss: 0.0006690573645755649\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6647401574736175\n",
      "[DEBUG] Loss: 0.00019699573749676347\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0002845386625267565\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00021667141118086874\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0016\n",
      "[DEBUG] Loss: 5.512124698725529e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5939895524669181\n",
      "[DEBUG] Loss: 0.0003054188273381442\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0003650237340480089\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.0003550559049472213\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 8.498495299136266e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6310278321001253\n",
      "[DEBUG] Loss: 0.09352350234985352\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1186\n",
      "[DEBUG] Loss: 0.00046276027569547296\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1187\n",
      "[DEBUG] Loss: 0.0005479220999404788\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1187\n",
      "[DEBUG] Loss: -0.09294832497835159\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5707256310781754\n",
      "[DEBUG] Loss: -0.053081586956977844\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0657\n",
      "[DEBUG] Loss: -0.053276125341653824\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1313\n",
      "[DEBUG] Loss: 0.00020256770949345082\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1313\n",
      "[DEBUG] Loss: 0.10864952206611633\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7785640825502687\n",
      "[DEBUG] Loss: -0.05382426828145981\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.4478\n",
      "[DEBUG] Loss: -0.05379499867558479\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.8966\n",
      "[DEBUG] Loss: 0.10837678611278534\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1836\n",
      "[DEBUG] Loss: 0.00018535609706304967\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7674604059980193\n",
      "[DEBUG] Loss: 0.00022966509277466685\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0004139188677072525\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0021\n",
      "[DEBUG] Loss: 0.0003072067047469318\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0029\n",
      "[DEBUG] Loss: 0.00012295292981434613\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7611656803358333\n",
      "[DEBUG] Loss: 0.0004032891010865569\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.000304525310639292\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00024328954168595374\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.0004337008867878467\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5347143529216966\n",
      "[DEBUG] Loss: 0.0008471648907288909\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0007377708097919822\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00039699929766356945\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00043230332084931433\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6631302997780661\n",
      "[DEBUG] Loss: 0.00023999001132324338\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00035598917747847736\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.0003286450810264796\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0022\n",
      "[DEBUG] Loss: 3.533578274073079e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6162075855148628\n",
      "[DEBUG] Loss: 0.02108229510486126\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0271\n",
      "[DEBUG] Loss: -0.050716422498226166\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1067\n",
      "[DEBUG] Loss: 0.03067636862397194\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1222\n",
      "[DEBUG] Loss: 0.0004910374991595745\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7105301588749734\n",
      "[DEBUG] Loss: -0.03589056059718132\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0591\n",
      "[DEBUG] Loss: -0.1072627454996109\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1811\n",
      "[DEBUG] Loss: 0.09982424229383469\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1635\n",
      "[DEBUG] Loss: 0.04393259063363075\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6888943155967008\n",
      "[DEBUG] Loss: 0.00043535622535273433\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: -0.053433530032634735\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0620\n",
      "[DEBUG] Loss: 0.0006580196204595268\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0619\n",
      "[DEBUG] Loss: 0.05407731980085373\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.626845103137443\n",
      "[DEBUG] Loss: 0.0004969427245669067\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.00026031548622995615\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0016\n",
      "[DEBUG] Loss: 0.0002777963818516582\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.0004230297636240721\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7527939483516277\n",
      "[DEBUG] Loss: 0.00023713638074696064\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0002083762374240905\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0002255872532259673\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00027744565159082413\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.4324831108924064\n",
      "[DEBUG] Loss: 0.00031969172414392233\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.0002601899323053658\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00020068812591489404\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n",
      "[DEBUG] Loss: 0.0002601899323053658\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.61565991963448\n",
      "[DEBUG] Loss: 0.0006571872509084642\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.00048012082697823644\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.00036341033410280943\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.0004197648959234357\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5457803341729424\n",
      "[DEBUG] Loss: 0.062465738505125046\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3826\n",
      "[DEBUG] Loss: -0.061982713639736176\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1654\n",
      "[DEBUG] Loss: 0.00039601419121026993\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1654\n",
      "[DEBUG] Loss: 0.00032360979821532965\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7417650379790343\n",
      "[DEBUG] Loss: -0.008200384676456451\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1445\n",
      "[DEBUG] Loss: 0.0003730198659468442\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1445\n",
      "[DEBUG] Loss: 0.08538523316383362\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1628\n",
      "[DEBUG] Loss: -0.07629382610321045\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7129917762403278\n",
      "[DEBUG] Loss: 0.0003413716913200915\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00019950946443714201\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.00040663365507498384\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.00019950946443714201\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5866999764225449\n",
      "[DEBUG] Loss: 0.0002448720042593777\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0002448720042593777\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n",
      "[DEBUG] Loss: 0.0002577696577645838\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0025\n",
      "[DEBUG] Loss: 0.00023197437985800207\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6817559399441248\n",
      "[DEBUG] Loss: 0.06727036088705063\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0525\n",
      "[DEBUG] Loss: -0.08267562091350555\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0439\n",
      "[DEBUG] Loss: 0.01595134101808071\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0415\n",
      "[DEBUG] Loss: 0.00020242008031345904\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6367255368427431\n",
      "[DEBUG] Loss: 0.05265123024582863\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1295\n",
      "[DEBUG] Loss: 0.00042680196929723024\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1295\n",
      "[DEBUG] Loss: 0.0526580847799778\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2315\n",
      "[DEBUG] Loss: -0.10413508117198944\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7144614136931998\n",
      "[DEBUG] Loss: 0.00041074701584875584\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00027939255232922733\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 5.9224534197710454e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00023960121325217187\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6231968208274075\n",
      "[DEBUG] Loss: 0.000460483250208199\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00023139864788390696\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.00038696284173056483\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.00015787826851010323\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7078964578574967\n",
      "[DEBUG] Loss: 0.0005586046609096229\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0005621462478302419\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00041834532748907804\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.00028837635181844234\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6634783924170504\n",
      "[DEBUG] Loss: -0.05257551744580269\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1429\n",
      "[DEBUG] Loss: 0.0002473918139003217\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1432\n",
      "[DEBUG] Loss: 0.05300220474600792\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0750\n",
      "[DEBUG] Loss: 0.0002473918139003217\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.8036430243635406\n",
      "[DEBUG] Loss: 0.0005415361374616623\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.0004720707074739039\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0006454131798818707\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0013\n",
      "[DEBUG] Loss: 0.00022926280507817864\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.675085955143564\n",
      "[DEBUG] Loss: 0.00032792246202006936\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.00038144749123603106\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00033526483457535505\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.000267055060248822\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7670252607382912\n",
      "[DEBUG] Loss: -0.030127540230751038\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0132\n",
      "[DEBUG] Loss: 0.09232134371995926\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0510\n",
      "[DEBUG] Loss: -0.03047662414610386\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0492\n",
      "[DEBUG] Loss: -0.030252764001488686\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7141768544360203\n",
      "[DEBUG] Loss: 0.0002352636365685612\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0002279893378727138\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.00021155264403205365\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n",
      "[DEBUG] Loss: 0.0002662489132490009\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6689803080996323\n",
      "[DEBUG] Loss: 0.00022660940885543823\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0749\n",
      "[DEBUG] Loss: -0.00827980786561966\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1319\n",
      "[DEBUG] Loss: -0.08462952077388763\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1984\n",
      "[DEBUG] Loss: 0.09374935925006866\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6166441695115994\n",
      "[DEBUG] Loss: 0.00047691413783468306\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: -0.047470591962337494\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0495\n",
      "[DEBUG] Loss: 0.00030368060106411576\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0495\n",
      "[DEBUG] Loss: 0.04781854897737503\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6795111623295892\n",
      "[DEBUG] Loss: 0.0003983537608291954\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0003749609168153256\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.0003115371218882501\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0005070522893220186\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6298536907958935\n",
      "[DEBUG] Loss: 0.00048189974040724337\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n",
      "[DEBUG] Loss: 0.00048642512410879135\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0028\n",
      "[DEBUG] Loss: 0.0003299684030935168\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0033\n",
      "[DEBUG] Loss: 0.0006475378759205341\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6162060639721169\n",
      "[DEBUG] Loss: 0.00017953143105842173\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00043960698531009257\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00032346692751161754\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0008\n",
      "[DEBUG] Loss: 0.0003142017812933773\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6894728139876434\n",
      "[DEBUG] Loss: 0.00031976657919585705\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0002556111430749297\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0004756283015012741\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 7.211082265712321e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.636733588722763\n",
      "[DEBUG] Loss: -0.030667457729578018\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0428\n",
      "[DEBUG] Loss: 0.09362417459487915\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1031\n",
      "[DEBUG] Loss: -0.03068612329661846\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0949\n",
      "[DEBUG] Loss: -0.030940091237425804\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5254379522550523\n",
      "[DEBUG] Loss: 0.0004331786185503006\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.031439539045095444\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3679\n",
      "[DEBUG] Loss: 0.0312529020011425\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.7369\n",
      "[DEBUG] Loss: -0.06197497993707657\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.7376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.824860588116106\n",
      "[DEBUG] Loss: 0.0002455805952195078\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00023241985763888806\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.0004486656980589032\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0016\n",
      "[DEBUG] Loss: 0.00029773369897156954\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.562591000065652\n",
      "[DEBUG] Loss: 0.00043089198879897594\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0005699130124412477\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00045007216976955533\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0005890931934118271\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5221743531074718\n",
      "[DEBUG] Loss: 0.0007322602323256433\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0007318960269913077\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0007326245540753007\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.0007322602905333042\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6021885601594822\n",
      "[DEBUG] Loss: 0.00015995875583030283\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0003497131692711264\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.0004226846795063466\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0028\n",
      "[DEBUG] Loss: 0.00028331641806289554\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7382267279361215\n",
      "[DEBUG] Loss: 0.00023796837194822729\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.000146147096529603\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.00018919812282547355\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0018\n",
      "[DEBUG] Loss: 0.0001834788708947599\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5764496302451643\n",
      "[DEBUG] Loss: 0.00025762084987945855\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: -0.030607054010033607\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0477\n",
      "[DEBUG] Loss: 0.09270328283309937\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0942\n",
      "[DEBUG] Loss: -0.06137002632021904\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6177820537476469\n",
      "[DEBUG] Loss: 0.00022436014842242002\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0003164262743666768\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.000367594271665439\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00035732443211600184\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6686183987707325\n",
      "[DEBUG] Loss: 0.00027751029119826853\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.00027751029119826853\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0023\n",
      "[DEBUG] Loss: 0.00027751029119826853\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0035\n",
      "[DEBUG] Loss: 0.00027751029119826853\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6540395592329911\n",
      "[DEBUG] Loss: -0.09317518025636673\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2665\n",
      "[DEBUG] Loss: 0.00021243591618258506\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2664\n",
      "[DEBUG] Loss: 0.062485650181770325\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1659\n",
      "[DEBUG] Loss: 0.031267259269952774\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7531225919467193\n",
      "[DEBUG] Loss: 0.00039234256837517023\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0091\n",
      "[DEBUG] Loss: 0.00021252146689221263\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0604\n",
      "[DEBUG] Loss: -0.05316980555653572\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1234\n",
      "[DEBUG] Loss: 0.05381198227405548\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7407271741803572\n",
      "[DEBUG] Loss: 0.000168635044246912\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0036\n",
      "[DEBUG] Loss: -0.005150616634637117\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0216\n",
      "[DEBUG] Loss: 0.00034673750633373857\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0257\n",
      "[DEBUG] Loss: 0.005593530833721161\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7188081940461776\n",
      "[DEBUG] Loss: 0.0006197685142979026\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0004447884566616267\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0002504407602827996\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: 0.00046415612450800836\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.40381132947746573\n",
      "[DEBUG] Loss: 0.013706937432289124\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0860\n",
      "[DEBUG] Loss: 0.05210813507437706\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1368\n",
      "[DEBUG] Loss: -0.1101505309343338\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2024\n",
      "[DEBUG] Loss: 0.04525559023022652\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6489979548769498\n",
      "[DEBUG] Loss: 0.0005612177774310112\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0025\n",
      "[DEBUG] Loss: 0.0004249527119100094\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0049\n",
      "[DEBUG] Loss: 0.0005573119269683957\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0049\n",
      "[DEBUG] Loss: 0.0007013886352069676\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.8306265878726609\n",
      "[DEBUG] Loss: -0.023007314652204514\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2788\n",
      "[DEBUG] Loss: 1.483168853155803e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2788\n",
      "[DEBUG] Loss: 0.1392255276441574\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.3156\n",
      "[DEBUG] Loss: -0.115281842648983\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.2336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.578371785908474\n",
      "[DEBUG] Loss: 0.00019253557547926903\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.0005053956992924213\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0004237368702888489\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n",
      "[DEBUG] Loss: 0.0005732793360948563\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7818551872260807\n",
      "[DEBUG] Loss: 0.00022073871514294297\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 6.611779826926067e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0012\n",
      "[DEBUG] Loss: 0.00038578303065150976\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0032\n",
      "[DEBUG] Loss: 0.00021031529468018562\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7683699920275493\n",
      "[DEBUG] Loss: 9.733198385220021e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.00013919260527472943\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 9.733198385220021e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 5.547136242967099e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6090450928381964\n",
      "[DEBUG] Loss: 0.0002473646018188447\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0031\n",
      "[DEBUG] Loss: 0.00030034087831154466\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0053\n",
      "[DEBUG] Loss: 0.0003613616863731295\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0043\n",
      "[DEBUG] Loss: 0.0005459957756102085\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6193092254188706\n",
      "[DEBUG] Loss: 0.00033879088005051017\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0027\n",
      "[DEBUG] Loss: 0.00017176983237732202\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0041\n",
      "[DEBUG] Loss: 0.00015442448784597218\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0041\n",
      "[DEBUG] Loss: 8.121620339807123e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7389112539277582\n",
      "[DEBUG] Loss: 0.0004094680189155042\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0017\n",
      "[DEBUG] Loss: 0.0004497388727031648\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0051\n",
      "[DEBUG] Loss: 0.00018926452321466058\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0064\n",
      "[DEBUG] Loss: 0.00024357209622394294\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5803690630060462\n",
      "[DEBUG] Loss: 0.030061274766921997\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0566\n",
      "[DEBUG] Loss: -0.05864929035305977\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0713\n",
      "[DEBUG] Loss: 0.0006349342875182629\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0713\n",
      "[DEBUG] Loss: 0.02981383167207241\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.5038806134124758\n",
      "[DEBUG] Loss: 0.00023308042727876455\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 7.241270213853568e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0007\n",
      "[DEBUG] Loss: -0.04608452692627907\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1178\n",
      "[DEBUG] Loss: 0.04658426344394684\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.47956945680856\n",
      "[DEBUG] Loss: 0.0004259195411577821\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.0003029637155123055\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0011\n",
      "[DEBUG] Loss: 0.0004564077244140208\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0021\n",
      "[DEBUG] Loss: 0.0006403399747796357\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6836944947259955\n",
      "[DEBUG] Loss: 0.00032460869988426566\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.052224721759557724\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0534\n",
      "[DEBUG] Loss: 0.00031853109248913825\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0534\n",
      "[DEBUG] Loss: -0.05170680582523346\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.7206838984000764\n",
      "[DEBUG] Loss: 0.0003683962859213352\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.00023670609516557306\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0003\n",
      "[DEBUG] Loss: 0.00034084805520251393\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 9.319197852164507e-05\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6459186919980757\n",
      "[DEBUG] Loss: 0.0005498395767062902\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0002\n",
      "[DEBUG] Loss: 0.0004651999333873391\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.00048797245835885406\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0005\n",
      "[DEBUG] Loss: 0.0003577876486815512\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of rewards : f16 and avg reward 0.6515328859276625\n",
      "[DEBUG] Loss: 0.0001532670867163688\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0001\n",
      "[DEBUG] Loss: 0.00037513207644224167\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0004\n",
      "[DEBUG] Loss: 0.0003773758071474731\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0010\n",
      "[DEBUG] Loss: 0.0003092377446591854\n",
      "[DEBUG] Params with grad: 392 / 1441\n",
      "[DEBUG] Grad norm: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=182, training_loss=0.0010957690152521295, metrics={'train_runtime': 3225.4564, 'train_samples_per_second': 0.227, 'train_steps_per_second': 0.057, 'total_flos': 0.0, 'train_loss': 0.0010957690152521295})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import is_bf16_supported\n",
    "from vlmgrpo import VLMGRPOTrainer\n",
    "from trl import GRPOConfig\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 2e-5,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bf16_supported(),\n",
    "    fp16 = not is_bf16_supported(),\n",
    "    per_device_train_batch_size = 4,\n",
    "    gradient_accumulation_steps = 4, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory,\n",
    "\n",
    "    # max_prompt_length = 2048,\n",
    "    max_completion_length = 128,\n",
    "    num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    # max_steps = 70,\n",
    "    save_steps = 15,\n",
    "    max_grad_norm = 1.0,\n",
    "    report_to = \"none\", #\"wandb\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs_grpo\",\n",
    "    # beta = 0.0\n",
    ")\n",
    "\n",
    "trainer = VLMGRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class=tokenizer, # MUST put unsloth processor here!\n",
    "    reward_processing_classes = tokenizer, #Here also\n",
    "    reward_funcs = [\n",
    "        compute_reward,\n",
    "        # length_reward,\n",
    "        # drug_adverse_preservation_reward,\n",
    "        # calculate_visual_grounding_reward,\n",
    "        # domain_specific_hallucination_penalty,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = converted_dataset,\n",
    "    grad_verbose=True\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4297cf69-af87-4c8d-95aa-0abab8edb822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/charan_work/vlm-grpo\n"
     ]
    }
   ],
   "source": [
    "%cd vlm-grpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940dabb-2e7b-4577-87cb-0d993eb1fcc7",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "7a993f59c2b94c159191184cd7d7b87b",
      "bfeea77738244b10bd6fbc321891626e",
      "5b9540d56d894eafa1de84d10ce9e4e1",
      "e73f9bd55e8d46bdb213e97b5096adcd",
      "68aa38cb416a4701b18c5f7e51628606",
      "b1647f85b71a4f38992e0528b0cfe681",
      "364d998715ca4c6c80e3389ece9875fd"
     ]
    },
    "id": "7940dabb-2e7b-4577-87cb-0d993eb1fcc7",
    "outputId": "2606366e-c247-46e9-af9c-06151158ca45",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7917d20cb6e347db8cdb98a5d46a7d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22dc41b2016417895d4b05cece797cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59943a93c2d144479a2d9a34fd84b89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/164M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9564f61539497cba7f4fa4d796bafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257cb956e1394f7ba61fc61f961d2a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41e1076aac042808a20b6eb39981d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.pt:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27ebc92462e44b6a1736c78afd6d7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/6.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Cherran/grpo_only_compute_later_l2e5_VL_medical_qwen2point5_7b/commit/ee41faf0e1b731e7e72cc9726dd1e7646f9638a7', commit_message='Upload folder using huggingface_hub', commit_description='', oid='ee41faf0e1b731e7e72cc9726dd1e7646f9638a7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Cherran/grpo_only_compute_later_l2e5_VL_medical_qwen2point5_7b', endpoint='https://huggingface.co', repo_type='model', repo_id='Cherran/grpo_only_compute_later_l2e5_VL_medical_qwen2point5_7b'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "model_path = \"outputs_grpo/checkpoint-180\"\n",
    "username = \"Cherran\"\n",
    "MODEL_NAME = \"grpo_only_compute_later_l2e5_VL_medical_qwen2point5_7b\"\n",
    "api = HfApi(token=  \"HF_API\")\n",
    "\n",
    "api.create_repo(\n",
    "    repo_id = f\"{username}/{MODEL_NAME}\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "api.upload_folder(\n",
    "    repo_id = f\"{username}/{MODEL_NAME}\",\n",
    "    folder_path = model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8708ab9-ebb1-4508-844b-711a1ff67c71",
   "metadata": {
    "id": "e8708ab9-ebb1-4508-844b-711a1ff67c71",
    "outputId": "8abefd9d-24f8-45f3-a024-448cbf329613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/charan_work\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a056a39-530b-4b1c-a21f-de47ee8b8c84",
   "metadata": {
    "id": "4a056a39-530b-4b1c-a21f-de47ee8b8c84",
    "outputId": "ed3f9041-969d-4bdb-ac75-608aa9d0119b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Links</th>\n",
       "      <th>Posts</th>\n",
       "      <th>Preprocessed Posts</th>\n",
       "      <th>drug_names</th>\n",
       "      <th>adverse_effects</th>\n",
       "      <th>severity</th>\n",
       "      <th>physical_adverse_effects</th>\n",
       "      <th>non_physical_adverse_effects</th>\n",
       "      <th>side_harmful_effects</th>\n",
       "      <th>...</th>\n",
       "      <th>phy_summary</th>\n",
       "      <th>non_phy_summary</th>\n",
       "      <th>VL_qwen_phy_sum_5rew_visualgr_grpo_lr2e5</th>\n",
       "      <th>VL_qwen_non_phy_sum_5rew_visualgr_grpo_lr2e5</th>\n",
       "      <th>VL_qwen_phy_sum_4rew_visualgr_grpo_lr2e5</th>\n",
       "      <th>VL_qwen_non_phy_sum_4rew_visualgr_grpo_lr2e5</th>\n",
       "      <th>VL_qwen_phy_sum_grpo_3rew_lr2e5</th>\n",
       "      <th>VL_qwen_non_phy_sum_3rew_grpo_lr2e5</th>\n",
       "      <th>VL_qwen_phy_sum_only_drugADV_grpo_lr2e5</th>\n",
       "      <th>VL_qwen_non_phy_sum_only_drugADV_grpo_lr2e5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://csn.cancer.org/discussion/comment/1239...</td>\n",
       "      <td>Xeloda on the Web.. Awesome website\\n  I switc...</td>\n",
       "      <td>xeloda on the web awesome website i switched o...</td>\n",
       "      <td>Xeloda</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mild</td>\n",
       "      <td>HandFoot syndrome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Xeloda is associated with adverse drug reactio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xeloda is associated with adverse effects such...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A patient receiving Xeloda treatment has devel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The image shows a patient experiencing physica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xeloda is associated with adverse effects incl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Links  \\\n",
       "0           0  https://csn.cancer.org/discussion/comment/1239...   \n",
       "\n",
       "                                               Posts  \\\n",
       "0  Xeloda on the Web.. Awesome website\\n  I switc...   \n",
       "\n",
       "                                  Preprocessed Posts drug_names  \\\n",
       "0  xeloda on the web awesome website i switched o...     Xeloda   \n",
       "\n",
       "  adverse_effects severity physical_adverse_effects  \\\n",
       "0             Yes     Mild        HandFoot syndrome   \n",
       "\n",
       "  non_physical_adverse_effects side_harmful_effects  ...  \\\n",
       "0                          NaN                  NaN  ...   \n",
       "\n",
       "                                         phy_summary non_phy_summary  \\\n",
       "0  Xeloda is associated with adverse drug reactio...             NaN   \n",
       "\n",
       "            VL_qwen_phy_sum_5rew_visualgr_grpo_lr2e5  \\\n",
       "0  Xeloda is associated with adverse effects such...   \n",
       "\n",
       "  VL_qwen_non_phy_sum_5rew_visualgr_grpo_lr2e5  \\\n",
       "0                                          NaN   \n",
       "\n",
       "            VL_qwen_phy_sum_4rew_visualgr_grpo_lr2e5  \\\n",
       "0  A patient receiving Xeloda treatment has devel...   \n",
       "\n",
       "  VL_qwen_non_phy_sum_4rew_visualgr_grpo_lr2e5  \\\n",
       "0                                          NaN   \n",
       "\n",
       "                     VL_qwen_phy_sum_grpo_3rew_lr2e5  \\\n",
       "0  The image shows a patient experiencing physica...   \n",
       "\n",
       "  VL_qwen_non_phy_sum_3rew_grpo_lr2e5  \\\n",
       "0                                 NaN   \n",
       "\n",
       "             VL_qwen_phy_sum_only_drugADV_grpo_lr2e5  \\\n",
       "0  Xeloda is associated with adverse effects incl...   \n",
       "\n",
       "  VL_qwen_non_phy_sum_only_drugADV_grpo_lr2e5  \n",
       "0                                         NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_val = pd.read_csv('val_VL_medical_qwen_draft_5rewards_grpo_only_drugADV.csv')\n",
    "df_val.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7849253-dbb5-44d8-a0f9-7951637e23a3",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "1333e62e7c524785858383b532ad198f",
      "a1d128eb7bab45c8963dbe6dc33771c0",
      "128f7cdb8d4d4b91928e9377c870b14f"
     ]
    },
    "id": "d7849253-dbb5-44d8-a0f9-7951637e23a3",
    "outputId": "6bf0d9a2-353d-4602-cb87-31f84f470aa5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c4d702f2e34caeb389e5c389e0c679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d0af72f30743cca9af4c2106a3af51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/29.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5ff8ad615749f0a1a07ccb819dfe96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'phy_prompt', 'non_phy_prompt', 'phy_summary', 'non_phy_summary', 'drug_names', 'non_physical_adverse_effects', 'physical_adverse_effects'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Cherran/GRPO_actualvalid_legit_medical_summaries\", split = 'train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed29f2",
   "metadata": {},
   "source": [
    "you can skip this step, no need to add dummy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baeaa343-815c-485c-be5a-a0c10fa03b9c",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "61843442ab0d47d49d905d8492832de5"
     ]
    },
    "id": "baeaa343-815c-485c-be5a-a0c10fa03b9c",
    "outputId": "d5f41902-22ef-4424-cca4-3e7a46a962da"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee672b23b97f44cea0dcaa127ffe006b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "dummy_image = Image.new('RGB', (512, 512), color = 'black')\n",
    "\n",
    "def add_dummy_image(example):\n",
    "    if not example[\"image\"]:\n",
    "        example[\"image\"] = [dummy_image]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(add_dummy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04675660-1d34-4963-8cbd-6b51fd36a604",
   "metadata": {
    "id": "04675660-1d34-4963-8cbd-6b51fd36a604"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def generate_response(sample, prompt_type='phy_prompt', temperature=1.0):\n",
    "\n",
    "    # --- Part 1: Construct the conversation ---\n",
    "\n",
    "    user_content = [\n",
    "        {\"type\": \"text\", \"text\": sample[prompt_type]}\n",
    "    ]\n",
    "\n",
    "    images = sample.get(\"image\", [])\n",
    "    if images and not isinstance(images, list):\n",
    "        images = [images]\n",
    "\n",
    "    # --- New: Image Resizing Logic ---\n",
    "    processed_images = []\n",
    "    if images:\n",
    "        for img_data in images:\n",
    "            # Open the image whether it's a path (str) or already a PIL Image\n",
    "            img = Image.open(img_data) if isinstance(img_data, str) else img_data\n",
    "\n",
    "            # Resize the image and append to the new list\n",
    "            resized_img = img.resize((512, 512))\n",
    "            processed_images.append(resized_img)\n",
    "\n",
    "    for _ in processed_images:\n",
    "        user_content.append({\"type\": \"image\"})\n",
    "\n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\": user_content}\n",
    "    ]\n",
    "\n",
    "    final_prompt_string = tokenizer.apply_chat_template(\n",
    "        conversation, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # --- Part 2: Conditionally tokenize inputs ---\n",
    "\n",
    "    # Use the new 'processed_images' list\n",
    "    if processed_images:\n",
    "        print(\"Processing with text and resized images (512x512)...\")\n",
    "        inputs = tokenizer(\n",
    "            text=final_prompt_string,\n",
    "            images=processed_images, # Pass the resized images\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "    else:\n",
    "        print(\"Processing with text only...\")\n",
    "        inputs = tokenizer(\n",
    "            text=final_prompt_string,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "    # --- Part 3: Generate and decode response ---\n",
    "\n",
    "    output_ids = model.generate(**inputs, max_new_tokens=128, use_cache=True, temperature=temperature, min_p=0.1)\n",
    "\n",
    "    input_ids_length = inputs[\"input_ids\"].shape[1]\n",
    "    newly_generated_ids = output_ids[:, input_ids_length:]\n",
    "\n",
    "    response_text = tokenizer.batch_decode(newly_generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    return response_text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f272d071-c42c-4e2b-8cfe-5a4faff89926",
   "metadata": {
    "id": "f272d071-c42c-4e2b-8cfe-5a4faff89926",
    "outputId": "296d1dda-ccce-4e05-ddc4-5d8a3205f5f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512>],\n",
       " 'phy_prompt': 'You are an excellent medical paragraph generator. I have drug names and Adverse Drug reactions Keywords. Consolidate all information in one paragrah without adding any extra knowledge or text.\\n  drug_names: ipilumumab, nivomulab, antihistamines, Imodium, oral steroids\\n  physical_adverse_effects: itchy rash, skin crawling sensation, diarrhoea, loss of appetite, weight loss (lost a stone and a half), immunotherapy induced colitis\\n\\n  Strcitly output the paragraph no explanations.\\n',\n",
       " 'non_phy_prompt': '',\n",
       " 'phy_summary': 'Ipilimumab and nivolumab, along with antihistamines, Imodium, and oral steroids, may lead to a range of adverse physical effects including itchy rash, skin crawling sensation, diarrhea, loss of appetite, significant weight loss (up to a stone and a half), and immunotherapy-induced colitis.',\n",
       " 'non_phy_summary': 'nan',\n",
       " 'drug_names': 'ipilumumab, nivomulab, antihistamines, Imodium, oral steroids',\n",
       " 'non_physical_adverse_effects': 'nan',\n",
       " 'physical_adverse_effects': 'itchy rash, skin crawling sensation, diarrhoea, loss of appetite, weight loss (lost a stone and a half), immunotherapy induced colitis'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b74ec1-b52c-4825-9eae-c898531bf2fa",
   "metadata": {
    "id": "a8b74ec1-b52c-4825-9eae-c898531bf2fa",
    "outputId": "4ef24cbd-6bdf-471e-a97d-b5c43279fd09",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:11<59:15, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xeloda is associated with physical adverse effects, including Hand-Foot syndrome, characterized by redness and swelling on the palms of the hands and soles of the feet. The image shows a close-up of a hand and feet affected by these symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:13<29:12,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xeloda, Ibuprophen, Voltaren, Ibrance, Xegeva, and Immpower are associated with various physical adverse effects including bone pain, rib pain, back pain, nausea, and a touchy stomach.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:14<17:54,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and aromatase inhibitors are associated with severe physical adverse effects including severe bone pain and bleeding.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [00:15<08:56,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligard, Lupron, and Testosterone are associated with physical adverse effects including hot flashes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [00:18<10:23,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percoset and Taxotere are associated with various physical adverse effects, including swelling in the legs and ankles, numbness in the feet, loss of feeling in the fingers and left side of the face, nausea, uncontrollable diarrhea, hair loss (bald patches), fallen off toenails and fingernails, stomach problems, and watery eyes. The image shows a foot with visible swelling and bruising on the ankle.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/300 [00:20<10:05,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligard, Casodex, Zoladex, Cyproterone, Abiraterone acetate, MDV3100, Ketoconazole, and Fosamax are associated with various adverse drug reactions, including physical effects such as bone loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:21<08:18,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentin is associated with physical adverse effects including diarrhea and significant weight loss of 25 pounds.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:22<04:13,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antibiotics and Aquaphor have been associated with various adverse effects, including hoarseness, a swollen throat, neck burns, significant weight loss of 75 pounds, and the need for a feeding tube insertion.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/300 [00:23<04:04,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effexor is associated with physical adverse effects, including a craniotomy scar.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/300 [00:24<04:32,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin, Epirubicin, and 5-FU are associated with various adverse drug reactions, including physical effects such as mouth sores, dehydration, and dumping syndrome.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/300 [00:25<04:22,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erbitux is associated with physical adverse effects including acne and pain from a tonsillectomy.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/300 [00:26<04:07,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hormone treatment and chemotherapy are associated with significant pain as a physical adverse effect.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [00:27<04:15,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin and Taxol are associated with physical adverse effects including groin pain, a small nodule, and slight nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/300 [00:28<05:25,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avastin, leucovorin, fluorouracil, oxaliplatin, and regorafenib are associated with various adverse drug reactions, including physical effects such as pain, significant weight loss (110 lbs), and difficulty eating properly.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/300 [00:30<04:59,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotuxin and morphine are associated with various physical adverse effects, including congestive heart failure, damaged heart, chronic and severe arrhythmias, early osteoarthritis, fibromyalgia, fatigue, and nerve damage.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:33<05:21,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin, Viscous Lidocaine, Sucralfate, Gelclair, and Nivolumab are associated with various physical adverse effects including tinnitus, mucositis, sore throat, nausea, vomiting, mouth sores, dry mouth, changes in taste, exterior burns, bloating, night cramps, and constipation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/300 [00:33<04:27,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/300 [00:35<05:03,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin and Paclitaxel (Taxol) are associated with various adverse drug reactions, including physical effects such as fatigue, pain from road bumps post-surgery, infection, and delayed wound healing.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/300 [00:36<05:12,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin, Paclitaxel, Decadron, Neulasta, and Neupogen are associated with various adverse drug reactions, including bone pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/300 [00:37<04:14,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-FU, Xeloda, Cisplatin, and Epirubicin are associated with various adverse drug reactions, including physical effects such as infection in incisions.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/300 [00:38<03:58,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decadron is associated with physical adverse effects including hair loss and sore ear.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/300 [00:39<04:12,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbo, Gemzar, Avastin, and Miralax are associated with various adverse drug reactions, including physical effects such as fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/300 [00:40<04:09,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole is associated with physical adverse effects including restless leg syndrome, irritable bladder, and constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/300 [00:42<04:49,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol, tramadol, and oral morphine are associated with various physical adverse effects, including waves of dizziness, flushes, pressure in the ears and jaw area, and painful trapped wind.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/300 [00:42<04:28,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects including tiredness, headaches, and hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 33/300 [00:44<04:42,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrataXRT and Flaminal Forte are associated with physical adverse effects including moist desquamation, weeping radiation burns, sore burns, and pus formation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 34/300 [00:45<04:47,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin is associated with physical adverse effects including numbness in fingers and toes, a tingling sensation in fingers and toes, and cold fingers.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/300 [00:46<05:28,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipilimumab and nivolumab are associated with physical adverse effects including a red rash, pain, itching, and burning. The image shows a skin area with a reddened, slightly raised texture, indicative of these symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 36/300 [00:49<06:52,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipilimumab and Nivolumab are associated with physical adverse effects including a red, itchy, burning rash that can flare up on the face. The patient is using antihistamine and applying Dermol 500 lotion for relief. Physical examination reveals a widespread, reddened rash across the back.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 37/300 [00:49<05:50,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVBD is associated with physical adverse effects including heartburn and a burning sensation in the chest.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 38/300 [00:52<06:53,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol, hydrocortisone, antihistamine, steroids, omeprazole, domperidone, and Rennie are associated with various physical adverse effects including high temperature, raised heart rate, severe body rigors, difficulty in breathing, and bad heartburn.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/300 [00:52<04:28,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects including extreme fatigue and feeling out of breath.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 41/300 [00:53<04:16,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loperamide (Imodium) is associated with physical adverse effects including electric shock sensations and tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/300 [00:54<04:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with physical adverse effects including hot flushes and night sweats.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/300 [00:55<04:22,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Exemestane are associated with physical adverse effects including hot flushes, night sweats, joint pain, and soreness in joints and muscles.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/300 [00:57<05:19,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab and Nivolumab are associated with various adverse drug reactions, including physical effects such as an all-over body rash and curly hair. The image shows a close-up of skin with numerous red spots and patches, indicative of a rash.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/300 [00:59<05:49,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivolumab is associated with various adverse effects, including joint ache, slight itchy rash, and vitiligo. The image shows a close-up of a patient's face with visible skin changes, possibly related to these physical adverse effects.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 46/300 [01:01<06:44,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipilimumab, nivolumab, antihistamines, Imodium, and oral steroids are associated with various physical adverse effects including an itchy rash, a skin crawling sensation, diarrhea, loss of appetite, weight loss (lost a stone and a half), and immunotherapy-induced colitis.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 47/300 [01:02<06:11,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC, docetaxel, and zoladex are associated with physical adverse effects including mild skin and nail reactions, muscle weakness, and breathlessness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/300 [01:03<05:27,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel and steroids are associated with physical adverse effects including water retention and puffiness in hands and feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 49/300 [01:04<05:11,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC, Paclitaxel, and docetaxel are associated with physical adverse effects including hair loss, joint pain, and muscle pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/300 [01:06<05:31,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, Filgrastim, and Herceptin are associated with various physical adverse effects including raised heart rate, rashes, pins and needles in fingertips, loss of appetite, and a horrible taste.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/300 [01:07<05:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Ribociclib are associated with physical adverse effects including itching, skin sloughing, small bumps, and bleeding.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/300 [01:08<04:48,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steroid cream and antihistamines may cause physical adverse effects including reddish skin, little lumps, and itching.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/300 [01:09<05:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fexofenadine Hydrochloride, Ribociclib, and Letrozole are associated with physical adverse effects including grogginess, nausea, and a thumping headache.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/300 [01:11<04:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amnidex, Exmestane, and Toxamoxin are associated with physical adverse effects including swollen hands and swollen ankles. The image shows a person wearing high-heeled shoes, highlighting the swelling in their ankles.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 56/300 [01:13<05:26,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morphine, ibuprofen, and various antibiotics can lead to a range of physical adverse effects including pain, saddle anaesthesia, difficulty urinating, difficulty with bowel movements, decreased sensitivity, numbness, pins and needles, shooting pains, muscle wasting, spinal fluid leak, swelling and redness at the surgical site, and constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/300 [01:14<05:09,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anti-sickness medications and steroids may be associated with physical adverse effects including hair loss, severe pain in bones and joints, and terrible constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 58/300 [01:15<04:45,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Exemestane are associated with physical adverse effects including hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 59/300 [01:16<05:08,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex, Exemestane, and Sage tablets are associated with physical adverse effects including hot flushes, night sweats, stiffness, and soreness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/300 [01:17<04:35,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with physical adverse effects including hot flushes and night sweats.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 61/300 [01:18<04:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects, including hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 62/300 [01:19<03:35,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folfox is associated with physical adverse effects, including hair thinning.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 63/300 [01:20<04:45,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nystan is associated with various physical adverse effects including fatigue, neuropathy (numb tingling), xerostomia (dry mouth), a swollen tongue, sluggish swallowing, and lymphedema (a wobbly sack under the chin).\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 64/300 [01:22<04:37,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capox (capecitabine) and oxaliplatin are associated with physical adverse effects including painful infusion and hot, tingly feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 66/300 [01:22<03:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xelox, Capox, and Folfiri are associated with physical adverse effects including neuropathy.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 67/300 [01:24<03:57,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-FU, Irovec, and Panitumumab are associated with physical adverse effects including rash. The image shows a close-up of an arm with numerous red spots and blisters, indicative of a skin reaction.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 68/300 [01:26<04:35,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epirubicin, cyclophosphamide, docetaxel, zoledronic acid, paracetamol, steroids, anti-sickness tablets, and filgrastin are associated with various adverse drug reactions, including headaches.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 69/300 [01:27<04:10,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso is associated with extensive bruising of the lung and repeat infections as physical adverse effects.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 70/300 [01:27<03:46,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso is associated with physical adverse effects including wheezing and abnormal breathing.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 71/300 [01:28<04:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso and Doxycycline are associated with various adverse effects, including physical symptoms such as wheezing, worsening of breathing, dry skin, and acne.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 73/300 [01:30<03:53,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxaliplatin, Capox (a combination of oxaliplatin and capecitabine), and Capecitabine are associated with various adverse drug reactions, including physical effects such as neuropathy, numbness in the throat, and a prickling sensation in the hands.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 74/300 [01:32<04:35,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxaliplatin is associated with various physical adverse effects, including swelling of the throat, numbness in the jaw, numbness in the tongue, pins and needles sensations in the feet, pins and needles sensations in the hands, and a runny nose.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 75/300 [01:33<04:05,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbociclib is associated with physical adverse effects including tiredness and diarrhea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 76/300 [01:35<04:31,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbociclib is associated with physical adverse effects including mouth ulcers and thinning hair. The image shows a close-up of a mouth with visible redness and small sores, indicative of mouth ulcers.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 77/300 [01:35<03:58,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbociclib is associated with physical adverse effects, including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 78/300 [01:36<03:52,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and morphine are associated with physical adverse effects including dry skin, itchy skin, and mouth sores.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 79/300 [01:38<04:23,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oromorph is associated with physical adverse effects including sore skin, red skin, dry skin, itching, and burning. The image shows a close-up of a neck area with visible redness and irritation on the skin.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 80/300 [01:39<04:12,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and over-the-counter drugs can lead to various physical adverse effects including joint pain, migraine, nasal drip, and sore throat.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 81/300 [01:41<04:47,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC, Docetaxel, and Zoladex are associated with various physical adverse effects including vomiting, nausea, bad constipation, indigestion, hair loss, pain, chills, hot flushes, breathlessness, and fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 82/300 [01:42<04:32,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects including hot flushes, cold chills, tiredness, hip pain, and aching thighs.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/300 [01:43<04:35,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Exemestane, and Loratadine are associated with physical adverse effects including stiffness, aches, weight gain, sluggishness, and tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/300 [01:45<05:09,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemestane, letrozole, magnesium, calcium, Vitamin D, Vitamin K, starflower oil, hemp oil, and sage tablets are associated with various physical adverse effects including sore hips, stiffness, mildly sore hands and feet, and sore feet after sitting.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 85/300 [01:46<04:39,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pazopanib is associated with physical adverse effects including diarrhea, lower abdominal pain, and a bad taste in the mouth.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 86/300 [01:47<04:39,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorafenib and Regorafenib are associated with physical adverse effects including extreme fatigue, callouses on feet, and pain. The image shows a foot with visible callouses.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/300 [01:48<04:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolendronic acid is associated with physical adverse effects including joint pain and muscle weakness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 88/300 [01:49<03:42,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects including exhaustion, headache, and discomfort in the lower abdomen.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 89/300 [01:49<03:15,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects including nausea and headaches.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 90/300 [01:50<02:56,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis is associated with physical adverse effects including headache and flu-like symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 91/300 [01:51<02:54,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel is associated with physical adverse effects including fatigue, diarrhea, and lack of appetite.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/300 [01:52<03:17,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, Pertuzumab, Trastuzumab, and Denosumab are associated with various adverse drug reactions, including chemo mouth.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 93/300 [01:53<03:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, pertuzumab, and trastuzumab are associated with physical adverse effects including taste change.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 94/300 [01:54<03:48,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, marketed as OncoLife, is associated with various physical adverse effects including hair loss, nail changes, neuropathy, dry skin, nausea, and constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/300 [01:56<04:10,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keytruda and Pembro are associated with physical adverse effects including rash, night sweats, and headache. The image shows a close-up of skin with red, raised patches, indicative of a rash.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/300 [01:57<04:26,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, carboplatin, and Niraparib are associated with various physical adverse effects including joint pain, muscle pain, tingling in fingers and toes, fatigue, and loss of body hair.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/300 [01:58<03:51,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niraparib is associated with physical adverse effects including low blood counts and nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 98/300 [01:59<03:19,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxol is associated with physical adverse effects including tiredness and sickness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 99/300 [02:00<03:21,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin and parp inhibitors are associated with physical adverse effects including urine infections, blocked ureter, and stent placement.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 100/300 [02:02<04:29,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everolimus is associated with physical adverse effects including constant itching, dry and flaky skin (especially on feet and legs, around the nose, and forehead), a rash on the arms, chesty cough, and pain from a femur fracture. The image shows a close-up of skin with visible flaking and irritation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/300 [02:04<05:28,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everolimus and Cabozantinib are associated with physical adverse effects including foot-hand syndrome, cellulitis in the right foot and leg, thick dry skin on the feet, and cracked soles and heels. The image shows a close-up of a foot with thick, dry skin and cracked areas on the sole and heel.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 102/300 [02:05<04:35,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axitinib is associated with physical adverse effects, including hard skin on hands and feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 103/300 [02:06<04:05,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Tamoxifen are associated with physical adverse effects including hot flushes and achy ankles.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/300 [02:08<04:16,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ixazomib, Lenalidomide, dexamethasone, and isatuzumab are associated with various adverse drug reactions, including physical effects such as joint pain and muscle pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 106/300 [02:09<03:28,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex, Exemestane, and Emla cream are associated with various physical adverse effects including hot flushes, bad headaches, dizziness, aches and pains in joints, lack of energy, and nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 107/300 [02:11<03:45,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex, Exemestane, and Hemp Oil are associated with various physical adverse effects including hot flushes, night sweats, joint pain, muscle pain, sore feet, and hip stiffness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 108/300 [02:12<03:40,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niraparib is associated with physical adverse effects including stomach pain, a bloated abdomen, a lack of appetite, and occasional nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 109/300 [02:13<03:30,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capox, Xelox, and Folfox are associated with physical adverse effects including diarrhea and fluid output from a stoma.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 110/300 [02:13<03:13,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Exemestane are associated with physical adverse effects including hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/300 [02:15<02:33,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Exemestane are associated with physical adverse effects including hot flushes, joint pain, sore hips, and sore feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/300 [02:16<02:37,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enzalutamide is associated with physical adverse effects including dizziness, loss of balance, and night leg syndrome.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 114/300 [02:17<02:46,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and CBD oil are associated with physical adverse effects including excessive watery discharge and a slight lime green tinge in urine.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 115/300 [02:18<02:50,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects including urine discoloration, vaginal dryness, and stiffness in the mornings.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 116/300 [02:19<02:50,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrazole is associated with physical adverse effects including joint/bone pains and pain in the soles of the feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/300 [02:21<03:58,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertuzamab, trastuzumab, Zoledronic acid, and Anastrozole are associated with various adverse drug reactions, including severe blisters under the breast and joint and leg pains. The image shows a close-up of skin with redness and blisters, indicating potential physical side effects from these medications.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 118/300 [02:21<03:25,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole is associated with physical adverse effects, including hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 119/300 [02:23<03:30,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, filgrastim, and paracetamol are associated with various adverse drug reactions, including sore throat, flu-like symptoms, and heavy head.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/300 [02:24<03:31,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filgrastim and paracetamol are associated with various physical adverse effects including headache, diarrhoea, vomiting, nausea, tiredness, and sore mouth.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 122/300 [02:25<02:35,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doxorubicin and gemcitabine are associated with various adverse drug reactions, including lung collapse as a physical adverse effect.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 124/300 [02:26<02:20,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemestane and letrozole are associated with physical adverse effects including extreme joint pain, bone spurs, and inflammatory osteoarthritis, leading to reduced mobility.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/300 [02:27<02:23,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and anastrozole are associated with physical adverse effects including painful joints and bone spurs.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/300 [02:29<03:04,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine is associated with physical adverse effects including soreness in the right hand, a tingling sensation, a prickly sensation, swollen fingertips, slightly inflamed and red knuckles, difficulty bending fingers, and difficulty closing the hand to make a fist.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 127/300 [02:30<03:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine is associated with physical adverse effects including skin peeling and palmar-plantar erythrodynia.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 128/300 [02:31<03:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine is associated with physical adverse effects including sore hands, sore feet, redness, cracked skin, and peeling skin.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 129/300 [02:33<03:55,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine and Oxaliplatin are associated with physical adverse effects including a tingly feeling in the toes, red and flaky soles of the feet, and side effects on the fingers that may be indicative of neuropathy. The image shows peeling skin on the foot, which is consistent with these physical symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 131/300 [02:35<03:08,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vinorelbine, Carboplatin, and steroids are associated with various adverse drug reactions, including physical effects such as hair loss and extreme tiredness, as well as anti-sickness measures to manage these side effects.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 132/300 [02:36<02:52,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel is associated with physical adverse effects, including nail damage.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 133/300 [02:36<02:35,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with physical adverse effects, including flushing.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 134/300 [02:37<02:22,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoledex is associated with physical adverse effects, including discomfort from injections.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 135/300 [02:38<02:34,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Elma cream are associated with physical adverse effects including hot flushes, night sweats, and soreness at the injection site.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 136/300 [02:39<02:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and tamoxifen are associated with physical adverse effects including hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 137/300 [02:40<02:46,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemestane, letrozole, and zoladex are associated with various adverse drug reactions, including physical effects such as sore joints, hot flashes, and night sweats.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 138/300 [02:42<03:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zometa is associated with physical adverse effects including lymphoedema and arm swelling, as evidenced by the visible swelling on the patient's arms in the image. The patient also experiences aches.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 139/300 [02:43<03:08,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Cipla, and Accord are associated with physical adverse effects including freezing cold, uncontrollable shivers, smelly urine, and hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 141/300 [02:44<02:10,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol is associated with physical adverse effects including sneezes and a runny nose.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 142/300 [02:46<03:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEC, Docetaxel, ibuprofen, and paracetamol are associated with various physical adverse effects including constant left hip pain, buttock pain, leg pain, blurry vision, sensitive hands, sore feet described as feeling like walking on sponges, and an ache at the top front of the right leg.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/300 [02:47<03:09,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel is associated with various physical adverse effects, including peripheral neuropathy in the hands, legs, and feet, as well as constipation, hip pain, and muscle pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 144/300 [02:49<03:25,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viscotears is associated with physical adverse effects including numbness in fingers and legs, loss of feeling up to knees, no total feeling in toes, difficulty fastening buttons, weird sensations in feet, and being prone to dry eyes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 145/300 [02:50<03:14,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and Genesis are associated with various physical adverse effects including dry mouth, aches, pains, constant headache, blurred vision, and fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 146/300 [02:51<03:12,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex, tamoxifen, and exemestane are associated with physical adverse effects including hot flashes, night sweats, stiff joints, and muscle stiffness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 147/300 [02:53<03:15,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zytiga is associated with physical adverse effects including tiredness, fatigue, sore ribs, sternum pain, and aches in the legs.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 148/300 [02:55<04:13,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fec, Docetaxel, ibuprofen, and diclofenac are associated with various physical adverse effects including tiredness, sore and swollen mouth, sore eyes (as shown in the image), sensitive hands and feet, pain in the left buttock, pain extending down into the leg, and hip and buttock pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 149/300 [02:56<03:51,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin, Taxo, and Paracetamol are associated with various adverse drug reactions, including physical effects such as horrendous headaches and aching leg bones.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 151/300 [02:57<02:39,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-codamol, doxecital, and FEC are associated with physical adverse effects including achy bones in the legs and feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 152/300 [02:59<03:14,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alectinib is associated with physical adverse effects including extreme tiredness and a rash resembling sunburn on the face, characterized by redness and sensitivity to sunlight. The image shows a close-up of a person's face with visible redness and irritation on the cheeks and nose.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 153/300 [03:00<02:51,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OEPA and COPDAC are associated with physical adverse effects including hot flashes and thinner hair.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 154/300 [03:01<02:31,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abemaciclib is associated with physical adverse effects including stomach pains and fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 155/300 [03:03<03:04,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEC (a combination of Fluorouracil, Epirubicin, and Cisplatin) and Docetaxel are associated with various physical adverse effects, including tiredness, sore mouth, sensitivity in hands and face, and hip and buttock pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/300 [03:04<03:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxaliplatin and capecitabine are associated with various adverse drug reactions, including physical effects such as cold sensitivity, arm tingling, and feeling weak.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 157/300 [03:05<02:46,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC and Taxol are associated with physical adverse effects including whiteheads and sore spots on the jawline and cheeks.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 158/300 [03:06<02:38,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC, Patitaxel, and HP are associated with physical adverse effects including nausea, vomiting, dehydration, and water infections.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 159/300 [03:08<03:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, Herceptin, steroids, antihistamine, and stomach pill are associated with various physical adverse effects including fatigue, lethargy, nosebleeds, stomach issues, cough, peripheral neuropathy, and acne.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 160/300 [03:08<02:40,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with physical adverse effects including testicular shrinkage and lower backache.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 162/300 [03:09<01:55,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teva, Sun Pharma, and Accord are associated with physical adverse effects including bone and muscle aches and hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 163/300 [03:10<01:56,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC and Taxol are associated with physical adverse effects including whiteheads, sore spots, and spots on the face.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 164/300 [03:12<02:27,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, Herceptin, steroids, antihistamine, and stomach pill are associated with various physical adverse effects including tiredness, lethargy, nosebleeds, dodgy stomach, cough, peripheral neuropathy, and acne.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 165/300 [03:13<02:11,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin and EC are associated with physical adverse effects including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 166/300 [03:14<02:07,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OXY, cap tabs are associated with physical adverse effects including nausea and rehydration issues due to difficulties in drinking.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 168/300 [03:15<01:38,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolafer (ZOLADEX) is associated with physical adverse effects including heavy legs, hip ache, and hot sweats.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 169/300 [03:16<01:48,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertuzumab, trastuzumab, and docetaxel are associated with physical adverse effects including appetite suppression and diarrhea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 170/300 [03:16<01:46,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Palbociclib are associated with physical adverse effects including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 171/300 [03:18<02:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxotere (Paclitaxel) and Avastin are associated with various physical adverse effects including joint pains, aches, overwhelming tiredness, and nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 172/300 [03:20<02:30,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, capecitabine, pertuzumab, trastuzumab, and filgrastim are associated with various adverse drug reactions, including physical effects such as hair loss, tiredness, and dizziness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 173/300 [03:21<02:41,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxol, Pertuzumab, Carboplatin, and Heceptin are associated with various physical adverse effects including tiredness, funny tummy, nausea, acne, hair loss, and hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 176/300 [03:22<01:29,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venlofloxacin and tamoxifen are associated with physical adverse effects including hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 179/300 [03:24<01:19,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine, oxaliplatin, Domperidone, and Loperamide are associated with various physical adverse effects including pain, numbness, sensitive hands, lower arm pain, nausea, fatigue, diarrhea, and tingling hands.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 180/300 [03:25<01:30,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunitinib (Sutent) is associated with various physical adverse effects including tummy trouble, nausea, sore feet, dizzy spells, and sweaty shivers.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 181/300 [03:26<01:39,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dab/Tram is associated with physical adverse effects including fever, chills, fatigue, muscle pain, joint pain, and soreness in the legs.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 182/300 [03:27<01:32,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dab and tram are associated with physical adverse effects including fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 183/300 [03:27<01:35,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel (Taxol) and capecitabine are associated with physical adverse effects including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 184/300 [03:29<01:55,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTD, Velcade, Thalidomide, and dex are associated with various adverse drug reactions, including rapid weight gain, numbness in fingers, legs, feet, and toes, and extreme tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 185/300 [03:31<02:13,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dabrafenib and Trametinib are associated with various physical adverse effects including aching joints, hot and tender soles of feet, cataracts, hearing loss, difficulty concentrating, and balance issues.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 187/300 [03:32<01:43,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabozantinib and Thyroxine are associated with physical adverse effects including sore mouth, sore hands, sore feet, diarrhea, and tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 188/300 [03:33<01:59,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab, Prednisolone, and Naproxen are associated with various physical adverse effects including aches and pains across the neck and shoulders, a painful right wrist, fatigue, and difficulty sleeping.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 189/300 [03:35<02:06,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab and ibuprofen are associated with physical adverse effects including aching and tiredness in the joints, as well as pain across the neck, back, and arms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 190/300 [03:37<02:32,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folfiri, loperamide, and cetuximab are associated with various adverse effects, including physical symptoms such as diarrhea, hair thinning, and an acne-like rash on the face. The image shows a close-up of skin with numerous small red bumps and patches, indicative of an acne-like rash.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 192/300 [03:38<02:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cetuximab is associated with physical adverse effects including an acne-type rash and diarrhea. The image shows a close-up of skin with small, raised bumps and redness, indicative of an acne-type rash.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 193/300 [03:40<02:14,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin, Pertuzamab, and Letrozole are associated with various adverse drug reactions, including physical effects such as pain in the hands, clicking fingers, neuropathy (tingly and numb fingers), and morning aches and pains.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 194/300 [03:41<02:09,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara, Decapeptyl, and Letrozole are associated with physical adverse effects including joint pain in the knuckles/hands and nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 195/300 [03:42<02:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects including pain in joints and trigger finger, characterized by two fingers sticking straight.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 196/300 [03:43<01:55,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxol and Herceptin are associated with various adverse drug reactions, including numbness in the balls of the feet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 199/300 [03:44<01:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alendronic acid, calcium, and letrozole are associated with physical adverse effects including toothache and nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 200/300 [03:45<01:16,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alendronic Acid, statin, Letrozole, and antihistamine are associated with physical adverse effects including hives and indigestion.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [03:48<01:58,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Cipla, Accord, Sandoz, Femara, and Exemestane (Teva) are associated with various physical adverse effects including cracked hands, downy fuzz on the face, joint pain, retinal detachment, chest pain, dizziness, and an ulcer in the eye. The image shows a close-up of an eye with visible signs of retinal detachment.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 202/300 [03:49<01:48,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teva is associated with physical adverse effects including hot flushes, ankle aches, and weight gain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 203/300 [03:50<02:03,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prednisone and methotrexate are associated with various physical adverse effects including water retention, sweating, loss of balance, confusion, and an increased risk of type 2 steroid-induced diabetes. Additionally, patients may experience frequent falls due to these side effects.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 204/300 [03:52<01:59,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Anastrozole are associated with physical adverse effects including joint pain, stiffness in the knees, and pain in the hands and fingers.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 205/300 [03:52<01:48,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects including joint pain, stiffness, and a hunched posture.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 206/300 [03:53<01:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects including stiffness in the ankles and feet, as well as difficulty walking in the morning.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 207/300 [03:54<01:36,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and bisphosphonates are associated with physical adverse effects including knee pain and stiffness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 208/300 [03:57<02:10,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levothyroxine is associated with various physical adverse effects, including hair loss, greasy hair at the roots, dry hair at the ends, brown patches of skin on the forehead and nose, and sunburn on the arms and shoulders. The image shows a person with visible brown patches on the forehead and nose, consistent with the described physical symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 209/300 [03:58<02:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin is associated with physical adverse effects including difficulty swallowing, thick mucus, loss of saliva, a raspy voice, and weakness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 210/300 [03:59<01:44,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin is associated with physical adverse effects including bone pain, nausea, and extreme fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 211/300 [04:00<01:46,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexamethasone and Zofran are associated with physical adverse effects including vomiting bile, significant weight loss (almost 40 pounds), weakness, and a skeletal appearance.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 212/300 [04:01<01:38,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara is associated with physical adverse effects including joint pain, muscle weakness, tiredness, and back-ache.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 213/300 [04:02<01:32,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara and Co-Codamol are associated with physical adverse effects including headaches, backache, and fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 214/300 [04:02<01:21,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects, including fast heart beating.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 215/300 [04:04<01:26,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, cod liver oil, vitamin D, and glucosamine have been associated with physical adverse effects including lower back pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 216/300 [04:04<01:16,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with physical adverse effects, including joint pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 217/300 [04:05<01:17,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrazole, codliver oil, and calcium have been associated with physical adverse effects including a slight ache in leg joints.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 218/300 [04:07<01:33,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rituximab is associated with various physical adverse effects including flu-like symptoms, chronic fatigue, mouth ulcers (as shown in the image), cystitis, aching joints, knee strain, muscle weakness, and diarrhea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/300 [04:08<01:24,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutuximab is associated with physical adverse effects including joint aches and mouth ulcers.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 220/300 [04:09<01:28,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rituximab is associated with various physical adverse effects, including tiredness, nausea, leg pain, clicking and hissing in ears, and night sweats.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 221/300 [04:10<01:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abiraterone is associated with physical adverse effects, including water infections.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 222/300 [04:10<01:15,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolodex, Abiraterone, and Prednisolone are associated with physical adverse effects including joint pains.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 223/300 [04:12<01:27,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemestane and letrozole are associated with physical adverse effects including swollen stiff fingers, locking of the little finger, soreness in the right hand, difficulty with hand movement, and reliance on a walking stick.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 224/300 [04:13<01:25,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Domperidone are associated with physical adverse effects including dry cough, wheezing, bad throat, and severe nausea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 225/300 [04:14<01:21,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozol, omeprazole, calcium, and blood pressure tablets are associated with physical adverse effects including dry cough.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 226/300 [04:15<01:10,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramipril is associated with physical adverse effects, including a dry cough.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 227/300 [04:16<01:18,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and anastrozole are associated with physical adverse effects including joint pain, bone pain, muscle pain, and stiffness in the legs, knees, hips, and thighs.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 228/300 [04:17<01:12,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects including bone pain, joint pain, and jaw aches.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 229/300 [04:18<01:05,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with physical adverse effects including aching jaw and joint pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 230/300 [04:19<01:10,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keytruda is associated with various physical adverse effects, including higher than normal temperatures, joint aches, itching, appetite loss, and minor pain on the right side.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 231/300 [04:20<01:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrozilumab is associated with physical adverse effects, including headache.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 232/300 [04:21<01:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab (Ketrruda) is associated with physical adverse effects including loss of appetite, tiredness, and itchiness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 234/300 [04:22<00:51,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspirin and tamoxifen are associated with various physical adverse effects, including sweats, hot flushes, light-headedness, and faintness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 238/300 [04:23<00:30,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antibiotics can lead to various physical adverse effects including infection, fluid build-up, hot and inflamed breast, and menopausal flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 239/300 [04:24<00:39,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afatinib and Osimertinib are associated with various physical adverse effects, including rash, hair changes characterized by thicker and curlier patches, constipation, and a decrease in running performance.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 240/300 [04:25<00:43,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembro and steroid are associated with various physical adverse effects including fever, pneumonitis, diarrhea, loss of appetite, and weakness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 241/300 [04:27<00:52,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and Letrozole are associated with various physical adverse effects including foggy head, headache, disorientation, loss of balance, extreme bone pain, muscle pain, vaginal dryness, and itchiness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 242/300 [04:28<00:49,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sutent is associated with physical adverse effects including tiredness and pain from tumours.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 243/300 [04:29<00:50,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorafenib is associated with various adverse drug reactions, including physical effects such as nausea, diarrhea, and constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 244/300 [04:29<00:47,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorafenib is associated with physical adverse effects including nausea and diarrhea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 245/300 [04:31<00:54,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durvalumab is associated with various adverse drug reactions, including physical effects such as tiredness, psoriasis, chest pain, and cough.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 246/300 [04:31<00:49,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and HRT are associated with physical adverse effects including achy joints.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 247/300 [04:33<00:58,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole, Adcal D3, exemestane, and alendronic acid are associated with physical adverse effects including height loss, back pain, hip pain, hand aches, and aching joints.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 249/300 [04:34<00:44,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso, Osimertinib, Gefitinib, and Iressa are associated with physical adverse effects including severe lack of appetite and problems with nails.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 250/300 [04:37<01:05,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso, Loperamide, and paracetamol are associated with various physical adverse effects including bouts of diarrhea, frequent nausea, loss of appetite, a bad taste in the mouth, hair loss, broken fingernails, and tiredness. The image shows a hand with visibly damaged fingernails, indicating potential nail damage as a physical side effect of these medications.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 253/300 [04:37<00:34,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prembo is associated with physical adverse effects, including joint pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 254/300 [04:38<00:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab (Keytruda) and epacadostat are associated with physical adverse effects including disturbing itch on the skin.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 255/300 [04:40<00:40,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dab is associated with severe physical adverse effects including severe rigors, temperatures reaching 40 degrees Celsius, flu-like symptoms, constant nausea, and uncontrollable shaking episodes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 256/300 [04:42<00:49,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votrient and morphine are associated with physical adverse effects including facial hair turning completely white and the mouth becoming very dry and sore. The images show a close-up of a person's lips before and after treatment, highlighting the changes in skin texture and coloration.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 257/300 [04:43<00:48,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kadcyla, Herceptin, and Perjeta are associated with various physical adverse effects including tiredness, muscle pain, bone pain, and nails lifting.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 258/300 [04:44<00:52,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kadcyla, docetaxel, Herceptin, Perjeta, and denosumab are associated with various adverse drug reactions, including physical effects such as tiredness, muscle pain, joint pain, and neuropathy.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 259/300 [04:45<00:45,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niraparib is associated with physical adverse effects including nausea and fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 260/300 [04:46<00:46,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accord (Letrozole) and other brands like Cipla, Activis, Teva, Manx, and Femera are associated with physical adverse effects including painful hands.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 262/300 [04:47<00:31,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alectinib is associated with physical adverse effects including fatigue, skin irritation, and minor constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 263/300 [04:48<00:29,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alectinib is associated with physical adverse effects, including constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 264/300 [04:49<00:28,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alectinib and milk of magnesia are associated with physical adverse effects including constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 265/300 [04:49<00:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tecentriq is associated with physical adverse effects including dry mouth and loss of taste.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 267/300 [04:50<00:21,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aldara is associated with physical adverse effects including inflammation, burning, itching, flu-like symptoms, headache, and diarrhea.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 268/300 [04:52<00:25,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin, Ondansetron, Domperidone, and Dulcolax are associated with various adverse drug reactions, including metallic taste and constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 269/300 [04:52<00:23,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aldara cream is associated with physical adverse effects, including flu-like symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 270/300 [04:53<00:24,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara and Letrozole are associated with severe physical adverse effects including severe pain in hands and general stiffness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 271/300 [04:54<00:25,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara (letrozole) is associated with physical adverse effects including fatigue, knee pain, pain on sitting down, and a dripping nose.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 272/300 [04:56<00:27,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara, glucosamine, cod liver oil, and vitamin D are associated with physical adverse effects including aches and pains, sitting bone pain, and sacrum pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 273/300 [04:56<00:24,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara and Letrozole are associated with physical adverse effects including joint pain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 274/300 [04:57<00:22,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolendronic Acid is associated with physical adverse effects including tiredness and aches.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 275/300 [04:58<00:22,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Sertraline are associated with physical adverse effects including hot flushes and tender breasts.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/300 [04:59<00:22,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Sertraline are associated with physical adverse effects including trigger thumbs and aches and pains in the breast area.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 277/300 [05:00<00:22,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole, Exemestane, and Everolimus are associated with physical adverse effects including sore mouth, dry mouth, and mild stomach upset.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 278/300 [05:01<00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbociclib is associated with physical adverse effects, including hair thinning.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 279/300 [05:02<00:17,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbo is associated with physical adverse effects including hair snapping off and thinning.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 280/300 [05:02<00:16,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbo is associated with physical adverse effects including thinning hair and reduced ponytail thickness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 282/300 [05:04<00:13,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zopiclone is associated with various physical adverse effects including giddiness, tiredness, nausea, coughing, sweating, and a dull ache in the upper abdomen.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 283/300 [05:04<00:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zopiclone is associated with physical adverse effects, including tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 284/300 [05:06<00:15,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol, morphine, codeine, ibuprofen, and tramadol are associated with various physical adverse effects including pain below the ribs, night sweats, headaches, migraines, gassiness, and discomfort at the site of the drain.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 285/300 [05:08<00:17,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sando, Lanreotide, and other anti-nausea drugs are associated with strong pain relief but may also cause physical adverse effects including dreadful nausea, headaches, a runny nose, and a need to be close to a toilet.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 286/300 [05:09<00:15,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembro, interferon, and thyroxine are associated with physical adverse effects including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 287/300 [05:10<00:16,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembro is associated with physical adverse effects including an all-over body rash, with no freckles present on the skin. The image shows a person's back and shoulder area covered in small, red, raised spots.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 288/300 [05:11<00:13,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab is associated with physical adverse effects, including muscle soreness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 289/300 [05:12<00:11,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ixazomib, Revlimid, and Dex are associated with physical adverse effects including intestinal side effects.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 290/300 [05:13<00:10,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivolumab (Opdivo) and steroids are associated with physical adverse effects including breathlessness and tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 291/300 [05:14<00:09,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Arimidex, Exemestane, Tamoxifen, and Femara are associated with physical adverse effects including stiffness, ache, and headaches.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 292/300 [05:17<00:12,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabozantinib is associated with various physical adverse effects, including sore mouth, swollen feet, cuts on feet, skin on legs turning to leather and cracking, swollen legs, and red, raw, and bleeding skin on the buttocks and crack. The image shows a foot with dry, cracked skin, indicative of the physical symptoms experienced by patients taking Cabozantinib.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 293/300 [05:17<00:08,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabozantinib is associated with physical adverse effects, including vomiting.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 294/300 [05:18<00:07,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lactulose, diprobase, and Aveeno are associated with physical adverse effects including constipation, nausea, and burns on the neck.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 295/300 [05:20<00:06,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MST, metoclopramide, lactulose, senna, diprobase, and betnovate are associated with physical adverse effects including constipation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 296/300 [05:20<00:04,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin and Taxol are associated with physical adverse effects including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 297/300 [05:21<00:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carb and Taxol are associated with physical adverse effects including hair loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 298/300 [05:22<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxol is associated with physical adverse effects including leg pain, numbness in fingers, and numbness in toes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 299/300 [05:23<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-codamol is associated with physical adverse effects, including discomfort in the lower abdomen.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [05:24<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cape and morphine are associated with various physical adverse effects, including pain in the scar area, fatigue, dry mouth, indigestion, constipation, muscle weakness in the legs, and dizziness.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df_val['VL_qwen_phy_sum_only_rougeBl_grpo_lr2e5'] = ''\n",
    "\n",
    "for index in tqdm(range(0, len(dataset))):\n",
    "    sample = dataset[index]\n",
    "    if sample['phy_prompt'] == '' :\n",
    "        continue\n",
    "    response = generate_response(sample, prompt_type = 'phy_prompt', temperature = 1.0)\n",
    "    print(response)\n",
    "    df_val.at[index , 'VL_qwen_phy_sum_only_rougeBl_grpo_lr2e5'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec32701-dcd5-4c7e-91c0-c2ac99f8bbde",
   "metadata": {
    "id": "4ec32701-dcd5-4c7e-91c0-c2ac99f8bbde",
    "outputId": "66135391-d60b-4395-af86-9b80c3337a7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:02<03:29,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and aromatase inhibitors, such as letrozole and anastrozole, are commonly used for hormone therapy in breast cancer treatment. Non-physical adverse effects reported include anxiety, which some patients experience due to concerns about the potential link between these medications and the risk of uterine cancer.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [00:03<02:21,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percoset and Taxotere are associated with non-physical adverse effects including terrible night terrors and dizziness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:03<02:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentin is associated with non-physical adverse effects including depression, frustration, and disappointment.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:04<01:40,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antibiotics and Aquaphor may be associated with non-physical adverse effects including fear, feeling alone, and emotional distress.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/300 [00:05<02:01,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effexor is associated with non-physical adverse effects including depression, cognitive slowing, and spaciness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/300 [00:06<01:53,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erbitux is associated with non-physical adverse effects including anxiety and fear.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [00:07<01:58,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin and Taxol are associated with non-physical adverse effects including concern and anxiety regarding the cancer diagnosis.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/300 [00:08<02:57,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avastin, leucovorin, fluorouracil, oxaliplatin, and regorafenib are associated with non-physical adverse effects including loneliness, emotional distress, feelings of helplessness, and frustration.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/300 [00:09<02:36,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotuxin and morphine are associated with non-physical adverse effects including memory issues and cognitive problems.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/300 [00:10<02:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin is associated with non-physical adverse effects, including treatment fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:11<03:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin, viscous lidocaine, sucralfate, Gelclair, and Nivolumab are associated with non-physical adverse effects including upset, worried, and fearful feelings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/300 [00:12<03:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/300 [00:13<03:35,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carboplatin and Paclitaxel (Taxol) are associated with non-physical adverse effects including frustration and anxiety about health and treatment status.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/300 [00:14<02:02,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decadron may cause non-physical adverse effects such as feeling fuzzy, too sleepy, and experiencing tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/300 [00:14<01:54,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole is associated with non-physical adverse effects, including irritability.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/300 [00:15<02:18,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol, tramadol, and oral morphine are associated with non-physical adverse effects including head fog.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 32/300 [00:16<02:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with non-physical adverse effects, including insomnia.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 35/300 [00:18<02:31,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipiilimumab and nivolumab are associated with non-physical adverse effects, including feelings of being overwhelmed.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 40/300 [00:19<01:30,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with non-physical adverse effects, including frustration.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 42/300 [00:19<01:29,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with non-physical adverse effects, including anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 43/300 [00:20<01:46,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Exemestane are associated with non-physical adverse effects including anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 44/300 [00:21<02:14,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab and Nivolumab are associated with non-physical adverse effects such as fatigue and feeling at half speed.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 45/300 [00:22<02:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivolumab is associated with non-physical adverse effects, including tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 48/300 [00:23<01:48,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel and steroids are associated with non-physical adverse effects including paranoia about cancer cells.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 50/300 [00:24<01:58,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, Filgrastim, and Herceptin are associated with non-physical adverse effects that include feelings of being floored or overwhelmed.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/300 [00:25<02:16,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Ribociclib are associated with non-physical adverse effects including tears and emotional distress.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 52/300 [00:26<02:46,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steroid cream and antihistamines are associated with non-physical adverse effects including emotional distress, such as feeling unable to celebrate and crying due to itching.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 57/300 [00:27<01:35,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anti-sickness medications and steroids may cause non-physical adverse effects such as tiredness and a general feeling of being unwell.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 60/300 [00:28<01:21,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with non-physical adverse effects, including stress.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 62/300 [00:28<01:21,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folfox is associated with non-physical adverse effects, including extra sensitivity.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 68/300 [00:30<01:17,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epirubicin, cyclophosphamide, docetaxel, zoledronic acid, paracetamol, steroids, anti-sickness tablets, and filgrastin are associated with non-physical adverse effects including feeling extremely emotional and fluctuations between being positive and negative.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 70/300 [00:31<01:18,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso is associated with non-physical adverse effects, including feelings of nervousness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 79/300 [00:32<00:44,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oromorph is associated with non-physical adverse effects, including feelings of increased positivity.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 83/300 [00:33<00:47,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Exemestane, and Loratadine are associated with non-physical adverse effects including feeling down and experiencing desperation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 84/300 [00:35<01:12,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemestane, letrozole, magnesium, calcium, Vitamin D, Vitamin K, starflower oil, hemp oil, and sage tablets are associated with non-physical adverse effects such as flushes and night sweats.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 85/300 [00:35<01:22,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pazopanib is associated with non-physical adverse effects, including worry.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 86/300 [00:36<01:42,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorafenib and Regorafenib are associated with non-physical adverse effects that include a detrimental impact on positive outlook and mood.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 87/300 [00:37<01:51,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolendronic acid is associated with non-physical adverse effects, including flu-like symptoms.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 92/300 [00:38<01:16,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, Pertuzumab, Trastuzumab, and Denosumab are associated with non-physical adverse effects including shock.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 95/300 [00:39<01:08,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keytruda and Pembro are associated with non-physical adverse effects including tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 96/300 [00:41<01:37,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, carboplatin, and Niraparib are associated with non-physical adverse effects including trauma from surgery, worry about infections, and anxiety regarding the side effects of medication.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 97/300 [00:41<01:45,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niraparib is associated with non-physical adverse effects, including insomnia.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/300 [00:42<01:17,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everolimus is associated with non-physical adverse effects including worrying about potential hip or pelvis replacement and feeling not optimistic.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 104/300 [00:44<01:26,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ixazomib, Lenalidomide, dexamethasone, and isatuzumab are associated with non-physical adverse effects, including anxiety, which can be nerve-wracking for patients.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 106/300 [00:45<01:37,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex, Exemestane, and Emla cream are associated with non-physical adverse effects including feelings of being overwhelmed, described as \"I am a wimp.\"\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 109/300 [00:46<01:22,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capox, Xelox, and Folfox are associated with non-physical adverse effects including feeling torn about treatment options.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 110/300 [00:47<01:43,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Exemestane are associated with non-physical adverse effects including anxiety, feelings of being down, and a drained sense of energy.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 113/300 [00:48<01:19,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enzalutamide is associated with non-physical adverse effects, including memory loss.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 115/300 [00:49<01:15,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with non-physical adverse effects, including brain fog.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 116/300 [00:50<01:31,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrazole is associated with non-physical adverse effects including exhaustion, brain fog, crying daily, and emotional distress.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 117/300 [00:51<02:02,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pertuzamab, trastuzumab, Zoledronic acid, and Anastrozole are associated with non-physical adverse effects including struggles to walk.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 118/300 [00:52<02:03,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole is associated with non-physical adverse effects including stress and anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 119/300 [00:53<02:18,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel, filgrastim, and paracetamol are associated with non-physical adverse effects including feeling spaced out.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 124/300 [00:54<01:18,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemestane and letrozole are associated with non-physical adverse effects including feelings of being ignored and emotional distress related to the loss of an active life.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 125/300 [00:55<01:29,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and anastrozole are associated with non-physical adverse effects, including feelings of aging.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/300 [00:56<01:42,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine is associated with non-physical adverse effects, including feelings of aging or \"feeling old.\"\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 134/300 [00:57<00:43,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoledex is associated with non-physical adverse effects, including those that affect mental health.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 135/300 [00:58<00:52,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex and Elma cream are associated with non-physical adverse effects including anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 142/300 [00:59<00:39,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEC, Docetaxel, ibuprofen, and paracetamol are associated with non-physical adverse effects, including worry about the treatment effects on the body.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 143/300 [01:00<00:48,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel is associated with non-physical adverse effects, including a general feeling of being unwell.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 144/300 [01:01<00:57,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viscotears is associated with non-physical adverse effects, including disappointment over a missed chemotherapy session.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 146/300 [01:02<01:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex, tamoxifen, and exemestane are associated with non-physical adverse effects including anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 148/300 [01:03<01:21,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fec, Docetaxel, ibuprofen, and diclofenac are associated with non-physical adverse effects including worry about health, a feeling of being unable to engage in previous physical activities such as running and biking, and a sense of being limited in mobility.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 149/300 [01:04<01:29,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin, Taxo, and Paracetamol are associated with non-physical adverse effects including fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 152/300 [01:05<01:10,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alectinib is associated with non-physical adverse effects including feeling fed up and pressure to return to work.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 153/300 [01:06<01:17,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OEPA and COPDAC are associated with non-physical adverse effects including worry about hair appearance.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/300 [01:07<01:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxaliplatin and capecitabine are associated with non-physical adverse effects, including a lack of interest in food and lethargy.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 157/300 [01:08<01:17,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC and Taxol are associated with non-physical adverse effects including feelings of being down and feelings of upset about appearance.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 159/300 [01:09<01:20,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, Herceptin, steroids, antihistamine, and stomach pill are associated with non-physical adverse effects including difficulty sleeping and increased appetite.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 160/300 [01:10<01:24,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoladex is associated with non-physical adverse effects, including loss of libido.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 163/300 [01:11<01:05,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC and Taxol are associated with non-physical adverse drug reactions, including feelings of being down and feeling stupid for being upset.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 164/300 [01:12<01:23,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paclitaxel, Herceptin, steroids, antihistamine, and stomach pill are associated with non-physical adverse effects including difficulty sleeping and increased appetite.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 165/300 [01:13<01:24,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin and EC are associated with non-physical adverse effects including panic.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 166/300 [01:14<01:32,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OXY, cap tabs have been associated with non-physical adverse effects including feelings of dreadfulness and excessive sleeping.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 168/300 [01:15<01:19,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolaferex is associated with non-physical adverse effects including mood swings, grumpiness, and depression.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 170/300 [01:16<01:13,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Palbociclib are associated with non-physical adverse effects including fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 171/300 [01:17<01:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxotere (Paclitaxel) and Avastin are associated with non-physical adverse drug reactions, including concerns about overall health and wellbeing, as well as feelings of being worse after receiving Avastin.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 175/300 [01:19<01:07,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with non-physical adverse effects, including sleep disturbances characterized by waking up 3 or 4 times a night, as well as potential anxiety resulting from these sleep issues.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 179/300 [01:20<00:54,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capecitabine, oxaliplatin, Domperidone, and Loperamide are associated with non-physical adverse effects including difficulty focusing and a negative impact on mental health.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 183/300 [01:21<00:44,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docetaxel (Taxol) and capecitabine are associated with non-physical adverse effects including stress and emotional distress.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 184/300 [01:23<01:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTD, Velcade, Thalidomide, and dex are associated with non-physical adverse drug reactions including feeling like you're shaking inside, blurry eyes, brain fog, and difficulty concentrating.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 185/300 [01:24<01:13,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dabrafenib and Trametinib are associated with non-physical adverse drug reactions including panic, dark thoughts, feelings of despair, and stress regarding potential permanent impairment.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 188/300 [01:26<01:06,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab, Prednisolone, and Naproxen are associated with non-physical adverse effects that include hesitance about posting, concern over potential permanent effects, and an attempt to be optimistic.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 190/300 [01:27<01:15,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folfiri, loperamide, and cetuximab can cause non-physical adverse effects such as upset due to appearance and feeling self-conscious. The image shows a close-up of a person's face with red, irritated skin, indicating potential physical symptoms related to these medications.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 192/300 [01:29<01:10,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cetuximab is associated with non-physical adverse effects, including fatigue, which can manifest as a tendency to drop off for naps.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 195/300 [01:29<00:53,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with non-physical adverse effects including chills and hot flushes.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [01:31<00:36,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Cipla, Accord, Sandoz, Femara, exemestane, and Teva are associated with non-physical adverse effects including headaches and dizziness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 203/300 [01:32<00:38,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prednisone and methotrexate are associated with non-physical adverse effects including insomnia and feelings of being trapped in a cycle.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 204/300 [01:33<00:44,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Anastrozole are associated with non-physical adverse effects, including feelings of being miserable.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 205/300 [01:34<00:48,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with non-physical adverse effects, including a determination to continue treatment.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 208/300 [01:35<00:40,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levothyroxine is associated with non-physical adverse effects including difficulty with thought process and inability to think straight.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 209/300 [01:35<00:46,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cisplatin is associated with non-physical adverse effects including feelings of choking and emotional distress from the treatment experience.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 210/300 [01:36<00:49,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herceptin is associated with non-physical adverse effects, including nervousness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 211/300 [01:37<00:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dexamethasone and Zofran are associated with non-physical adverse effects including trepidation and a feeling of hopelessness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 212/300 [01:38<00:58,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara is associated with non-physical adverse effects, including fatigue.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 214/300 [01:39<00:47,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole is associated with non-physical adverse effects including anxiety attacks and memory issues.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 218/300 [01:40<00:32,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rituximab is associated with non-physical adverse effects including feelings of abandonment and frustration over the lack of support from the consultant.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 219/300 [01:41<00:40,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutiximab is associated with non-physical adverse effects including fatigue, low energy, stress, and feelings of being old.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 224/300 [01:42<00:25,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Domperidone are associated with non-physical adverse effects including irritability and difficulty functioning.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 227/300 [01:43<00:27,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and anastrozole are associated with non-physical adverse effects that include frustration and emotional strain, as implied by terms like \"awful\" and \"frustrating.\"\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 229/300 [01:44<00:26,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen is associated with non-physical adverse effects including feelings of being down and experiencing stress.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 232/300 [01:45<00:23,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab (Ketrruda) is associated with non-physical adverse effects including agitation.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 233/300 [01:46<00:29,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen, anastrazole, and aspirin are associated with non-physical adverse effects, including concerns about stomach problems.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 239/300 [01:47<00:17,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afatinib and Osimertinib are associated with non-physical adverse effects, including tiredness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 240/300 [01:47<00:19,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembro and steroid are associated with non-physical adverse effects including disappointment and confusion.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 241/300 [01:48<00:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamoxifen and Letrozole are associated with non-physical adverse effects including panic attacks and extreme anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 243/300 [01:49<00:22,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorafenib is associated with non-physical adverse effects, including nervousness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 244/300 [01:50<00:24,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorafenib is associated with non-physical adverse effects, including hope.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 250/300 [01:51<00:13,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagrisso, Loperamide, and paracetamol were associated with non-physical adverse effects including frustration.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 254/300 [01:52<00:13,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembrolizumab (Keytruda) and epacadostat are associated with non-physical adverse effects, including nervously looking for follow-up statistics.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 255/300 [01:53<00:15,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dab is associated with non-physical adverse effects, including relief about the treatment break.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 260/300 [01:54<00:13,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accord (Letrozole) is associated with non-physical adverse effects including brain fog, emotional reactions, and feelings of unhappiness. The drug is manufactured by Cipla, Activis, Teva, Manx, and Femera.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 261/300 [01:55<00:16,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, also known as Norvatis UK Femara, is associated with non-physical adverse effects including nervousness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 272/300 [01:56<00:06,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara, glucosamine, cod liver oil, and vitamin D are associated with non-physical adverse effects including being awake at night.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 273/300 [01:57<00:07,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Femara and Letrozole are associated with non-physical adverse effects including low mood and increased tendency to experience meltdowns.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 274/300 [01:58<00:08,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zolendronic Acid is associated with non-physical adverse effects, including fearfulness.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 275/300 [01:59<00:09,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole and Sertraline are associated with non-physical adverse effects including anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 277/300 [02:00<00:09,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anastrozole, Exemestane, and Everolimus are associated with non-physical adverse effects including anxiety.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 280/300 [02:01<00:07,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palbo is associated with non-physical adverse effects, including emotional distress related to appearance due to hair thinning.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 284/300 [02:02<00:05,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paracetamol, morphine, codeine, ibuprofen, and tramadol are associated with non-physical adverse effects including frustration and difficulty sleeping.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 286/300 [02:03<00:05,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembro, interferon, and thyroxine are associated with non-physical adverse effects including worry and anxiety about appearance.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 289/300 [02:04<00:03,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ixazomib, Revlimid, and Dex are associated with non-physical adverse effects including hypersensitivity to medication.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 291/300 [02:05<00:03,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letrozole, Arimidex, Exemestane, Tamoxifen, and Femara are associated with non-physical adverse effects including insomnia.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 297/300 [02:06<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carb and Taxol are associated with non-physical adverse effects including feeling self-conscious, feeling very tired, and feeling exhausted.\n",
      "Processing with text and resized images (512x512)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:07<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cape and morphine are associated with non-physical adverse effects, including mental confusion where patients may feel not completely with it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_val['VL_qwen_non_phy_sum_only_rougeBl_grpo_lr2e5'] = ''\n",
    "for index in tqdm(range(0, len(dataset))):\n",
    "    sample = dataset[index]\n",
    "    if sample['non_phy_prompt'] == '' :\n",
    "        continue\n",
    "    response = generate_response(sample, prompt_type = 'non_phy_prompt', temperature = 1.0)\n",
    "    print(response)\n",
    "    df_val.at[index , 'VL_qwen_non_phy_sum_only_rougeBl_grpo_lr2e5'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73442deb-c782-4758-b733-9041ad3e615b",
   "metadata": {
    "id": "73442deb-c782-4758-b733-9041ad3e615b",
    "outputId": "d7ec3a1b-e41b-4955-e489-2c57bb1005d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 176)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_val['VL_qwen_phy_sum_grpo_full_lr2e5'] == '') ,  sum(df_val['VL_qwen_non_phy_sum_grpo_full_lr2e5'] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9800e4ca-a061-4317-9550-0b9014429e03",
   "metadata": {
    "id": "9800e4ca-a061-4317-9550-0b9014429e03"
   },
   "outputs": [],
   "source": [
    "df_val.to_csv('val_VL_medical_qwen_draft_5rewards_grpo_only_drugADV_rougeBL.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7ade2-205c-4560-b386-0e544bd69d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
